<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Bayesian Statistics | A First Course in Probability and Statistics</title>
  <meta name="description" content="These are a collection of notes related to STAT 588 and 341/342 at Iowa State University. This is a work in progress." />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Bayesian Statistics | A First Course in Probability and Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="These are a collection of notes related to STAT 588 and 341/342 at Iowa State University. This is a work in progress." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Bayesian Statistics | A First Course in Probability and Statistics" />
  
  <meta name="twitter:description" content="These are a collection of notes related to STAT 588 and 341/342 at Iowa State University. This is a work in progress." />
  

<meta name="author" content="Nick Syring" />


<meta name="date" content="2022-11-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="bootstrap.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Statistical Inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a></li>
<li class="chapter" data-level="2" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html"><i class="fa fa-check"></i><b>2</b> Data Analysis and Statistical Inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#data-experiments-and-studies"><i class="fa fa-check"></i><b>2.1</b> Data, Experiments, and Studies</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#james-linds-scurvy-trial"><i class="fa fa-check"></i><b>2.1.1</b> James Lind’s Scurvy Trial</a></li>
<li class="chapter" data-level="2.1.2" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#framingham-heart-study"><i class="fa fa-check"></i><b>2.1.2</b> Framingham Heart Study</a></li>
<li class="chapter" data-level="2.1.3" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#harris-bank-sex-pay-study"><i class="fa fa-check"></i><b>2.1.3</b> Harris Bank Sex Pay Study</a></li>
<li class="chapter" data-level="2.1.4" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#large-aggregated-data-sets"><i class="fa fa-check"></i><b>2.1.4</b> Large, Aggregated Data Sets</a></li>
<li class="chapter" data-level="2.1.5" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#study-concepts"><i class="fa fa-check"></i><b>2.1.5</b> Study Concepts</a></li>
<li class="chapter" data-level="2.1.6" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#randomization-control-and-causation"><i class="fa fa-check"></i><b>2.1.6</b> Randomization, control, and causation</a></li>
<li class="chapter" data-level="2.1.7" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#populations-and-scope-of-inference"><i class="fa fa-check"></i><b>2.1.7</b> Populations and scope of inference</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#data-summaries"><i class="fa fa-check"></i><b>2.2</b> Data Summaries</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#numerical-summaries"><i class="fa fa-check"></i><b>2.2.1</b> Numerical Summaries</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#visual-summaries"><i class="fa fa-check"></i><b>2.2.2</b> Visual Summaries</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#statistical-inference"><i class="fa fa-check"></i><b>2.3</b> Statistical Inference</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="statistical-estimation.html"><a href="statistical-estimation.html"><i class="fa fa-check"></i><b>3</b> Statistical Estimation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="statistical-estimation.html"><a href="statistical-estimation.html#vocabulary"><i class="fa fa-check"></i><b>3.1</b> Vocabulary</a></li>
<li class="chapter" data-level="3.2" data-path="statistical-estimation.html"><a href="statistical-estimation.html#properties-of-estimators"><i class="fa fa-check"></i><b>3.2</b> Properties of Estimators</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="statistical-estimation.html"><a href="statistical-estimation.html#bias-and-unbiasedness"><i class="fa fa-check"></i><b>3.2.1</b> Bias and Unbiasedness</a></li>
<li class="chapter" data-level="3.2.2" data-path="statistical-estimation.html"><a href="statistical-estimation.html#minimum-variance-unbiased-estimators"><i class="fa fa-check"></i><b>3.2.2</b> Minimum Variance Unbiased Estimators</a></li>
<li class="chapter" data-level="3.2.3" data-path="statistical-estimation.html"><a href="statistical-estimation.html#mean-squared-error-and-bias-variance-tradeoff"><i class="fa fa-check"></i><b>3.2.3</b> Mean Squared Error and Bias-Variance tradeoff</a></li>
<li class="chapter" data-level="3.2.4" data-path="statistical-estimation.html"><a href="statistical-estimation.html#consistency"><i class="fa fa-check"></i><b>3.2.4</b> Consistency</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="statistical-estimation.html"><a href="statistical-estimation.html#finding-estimators---method-of-moments"><i class="fa fa-check"></i><b>3.3</b> Finding estimators - Method of Moments</a></li>
<li class="chapter" data-level="3.4" data-path="statistical-estimation.html"><a href="statistical-estimation.html#method-of-maximum-likelihood"><i class="fa fa-check"></i><b>3.4</b> Method of Maximum Likelihood</a></li>
<li class="chapter" data-level="3.5" data-path="statistical-estimation.html"><a href="statistical-estimation.html#properties-of-mles"><i class="fa fa-check"></i><b>3.5</b> Properties of MLEs</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>4</b> Sampling Distributions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-mean"><i class="fa fa-check"></i><b>4.1</b> Sample Mean</a></li>
<li class="chapter" data-level="4.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-variance"><i class="fa fa-check"></i><b>4.2</b> Sample Variance</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#large-sample-sampling-distribution-of-sample-variance"><i class="fa fa-check"></i><b>4.2.1</b> Large-sample sampling distribution of sample variance</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sampling-distribution-of-studentized-sample-mean"><i class="fa fa-check"></i><b>4.3</b> Sampling distribution of studentized sample mean</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#part-of-students-theorem---indepndence-of-overline-x_n-and-s_n2"><i class="fa fa-check"></i><b>4.3.1</b> Part of Student’s Theorem - Indepndence of <span class="math inline">\(\overline X_n\)</span> and <span class="math inline">\(S_n^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="sampling-distributions.html"><a href="sampling-distributions.html#differences-of-sample-means"><i class="fa fa-check"></i><b>4.4</b> Differences of Sample Means</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#standarized-difference"><i class="fa fa-check"></i><b>4.4.1</b> Standarized difference</a></li>
<li class="chapter" data-level="4.4.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#studentized-difference-equal-variances"><i class="fa fa-check"></i><b>4.4.2</b> Studentized difference, equal variances</a></li>
<li class="chapter" data-level="4.4.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#studentized-difference-unequal-variances"><i class="fa fa-check"></i><b>4.4.3</b> Studentized difference, unequal variances</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sampling-distributions.html"><a href="sampling-distributions.html#ratios-of-sample-variances"><i class="fa fa-check"></i><b>4.5</b> Ratios of Sample Variances</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>5</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="5.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#why-want-interval-valued-estimates"><i class="fa fa-check"></i><b>5.1</b> Why want interval-valued estimates?</a></li>
<li class="chapter" data-level="5.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#normal-population-mean-example"><i class="fa fa-check"></i><b>5.2</b> Normal population mean example</a></li>
<li class="chapter" data-level="5.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#other-exact-cis-for-normal-population-mean-and-variance-parameters"><i class="fa fa-check"></i><b>5.3</b> Other “Exact” CIs for normal population mean and variance parameters</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#population-mean-unknown-variance"><i class="fa fa-check"></i><b>5.3.1</b> Population mean, unknown variance</a></li>
<li class="chapter" data-level="5.3.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#population-variance-unknown-mean"><i class="fa fa-check"></i><b>5.3.2</b> Population variance, unknown mean</a></li>
<li class="chapter" data-level="5.3.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#two-normal-samples-comparing-means"><i class="fa fa-check"></i><b>5.3.3</b> Two normal samples, comparing means</a></li>
<li class="chapter" data-level="5.3.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#two-normal-samples-comparing-variances"><i class="fa fa-check"></i><b>5.3.4</b> Two normal samples, comparing variances</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#cis-for-proportions"><i class="fa fa-check"></i><b>5.4</b> CIs for proportions</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#a-single-bernoulli-proportion"><i class="fa fa-check"></i><b>5.4.1</b> A single Bernoulli proportion</a></li>
<li class="chapter" data-level="5.4.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#difference-of-two-bernoulli-proportions"><i class="fa fa-check"></i><b>5.4.2</b> Difference of two Bernoulli proportions</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#approximate-cis-based-on-mles"><i class="fa fa-check"></i><b>5.5</b> Approximate CIs based on MLEs</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#multivariate-case"><i class="fa fa-check"></i><b>5.5.1</b> Multivariate case</a></li>
<li class="chapter" data-level="5.5.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#the-delta-method"><i class="fa fa-check"></i><b>5.5.2</b> The Delta method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>6</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#notation"><i class="fa fa-check"></i><b>6.1</b> Notation</a></li>
<li class="chapter" data-level="6.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-outcomes"><i class="fa fa-check"></i><b>6.2</b> Hypothesis testing outcomes</a></li>
<li class="chapter" data-level="6.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#tests-based-on-a-normal-population"><i class="fa fa-check"></i><b>6.3</b> Tests based on a normal population</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-for-a-normal-mean-when-the-variance-is-known"><i class="fa fa-check"></i><b>6.3.1</b> Test for a normal mean when the variance is known</a></li>
<li class="chapter" data-level="6.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-for-a-normal-mean-when-the-variance-is-unknown"><i class="fa fa-check"></i><b>6.3.2</b> Test for a normal mean when the variance is unknown</a></li>
<li class="chapter" data-level="6.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-for-a-normal-population-variance"><i class="fa fa-check"></i><b>6.3.3</b> Test for a normal population variance</a></li>
<li class="chapter" data-level="6.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#example-the-lifetimes-of-infected-guinea-pigs"><i class="fa fa-check"></i><b>6.3.4</b> Example: The lifetimes of infected Guinea pigs</a></li>
<li class="chapter" data-level="6.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#tests-for-a-difference-of-normal-population-means"><i class="fa fa-check"></i><b>6.3.5</b> Tests for a difference of normal population means</a></li>
<li class="chapter" data-level="6.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-for-equality-of-normal-population-variances"><i class="fa fa-check"></i><b>6.3.6</b> Test for equality of normal population variances</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#likelihood-based-tests"><i class="fa fa-check"></i><b>6.4</b> Likelihood-based Tests</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wald-type-tests"><i class="fa fa-check"></i><b>6.4.1</b> Wald type tests</a></li>
<li class="chapter" data-level="6.4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#likelihood-ratio-tests"><i class="fa fa-check"></i><b>6.4.2</b> Likelihood ratio tests</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#chi-squared-tests-for-tabulated-data"><i class="fa fa-check"></i><b>6.5</b> Chi Squared tests for tabulated data</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#goodness-of-fit-tests"><i class="fa fa-check"></i><b>6.5.1</b> Goodness of fit tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>7</b> ANOVA</a>
<ul>
<li class="chapter" data-level="7.1" data-path="anova.html"><a href="anova.html#analysis-of-variance"><i class="fa fa-check"></i><b>7.1</b> Analysis of variance</a></li>
<li class="chapter" data-level="7.2" data-path="anova.html"><a href="anova.html#crop-data-in-depth-example"><i class="fa fa-check"></i><b>7.2</b> Crop data in-depth example</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="anova.html"><a href="anova.html#checking-the-equal-variance-assumption"><i class="fa fa-check"></i><b>7.2.1</b> Checking the equal variance assumption</a></li>
<li class="chapter" data-level="7.2.2" data-path="anova.html"><a href="anova.html#normality-and-alternatives-to-the-f-test"><i class="fa fa-check"></i><b>7.2.2</b> Normality and alternatives to the F test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>8</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simple-linear-regression-model"><i class="fa fa-check"></i><b>8.1</b> Simple linear regression model</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#estimation"><i class="fa fa-check"></i><b>8.1.1</b> Estimation</a></li>
<li class="chapter" data-level="8.1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#estimation-of-the-common-variance"><i class="fa fa-check"></i><b>8.1.2</b> Estimation of the common variance</a></li>
<li class="chapter" data-level="8.1.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-regression-slope-parameter"><i class="fa fa-check"></i><b>8.1.3</b> Inference for regression slope parameter</a></li>
<li class="chapter" data-level="8.1.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-on-the-conditional-mean-response"><i class="fa fa-check"></i><b>8.1.4</b> Inference on the conditional mean response</a></li>
<li class="chapter" data-level="8.1.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#prediction-of-responses-at-given-x-values"><i class="fa fa-check"></i><b>8.1.5</b> Prediction of responses at given x values</a></li>
<li class="chapter" data-level="8.1.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simultaneous-confidence-bands-for-the-regression-line"><i class="fa fa-check"></i><b>8.1.6</b> Simultaneous confidence bands for the regression line</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#example-house-prices-as-function-of-house-age"><i class="fa fa-check"></i><b>8.2</b> Example: House prices as function of house age</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fitting-the-regression"><i class="fa fa-check"></i><b>8.2.1</b> Fitting the regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>9</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#the-multiple-linear-regression-model"><i class="fa fa-check"></i><b>9.1</b> The Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="9.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#point-estimation"><i class="fa fa-check"></i><b>9.2</b> Point estimation</a></li>
<li class="chapter" data-level="9.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#sampling-distributions-1"><i class="fa fa-check"></i><b>9.3</b> Sampling Distributions</a></li>
<li class="chapter" data-level="9.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#inference-on-regression-coefficients"><i class="fa fa-check"></i><b>9.4</b> Inference on regression coefficients</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#example-housing-price-data"><i class="fa fa-check"></i><b>9.4.1</b> Example: Housing price data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="likelihood-based-inferences.html"><a href="likelihood-based-inferences.html"><i class="fa fa-check"></i><b>10</b> Likelihood-Based Inferences</a>
<ul>
<li class="chapter" data-level="10.1" data-path="likelihood-based-inferences.html"><a href="likelihood-based-inferences.html#wald-tests-and-cis"><i class="fa fa-check"></i><b>10.1</b> Wald tests and CIs</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="likelihood-based-inferences.html"><a href="likelihood-based-inferences.html#example-auto-insurance-claims"><i class="fa fa-check"></i><b>10.1.1</b> Example: Auto insurance claims</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i><b>11</b> Bootstrap</a>
<ul>
<li class="chapter" data-level="11.1" data-path="bootstrap.html"><a href="bootstrap.html#intro-to-the-bootstrap"><i class="fa fa-check"></i><b>11.1</b> Intro to the bootstrap</a></li>
<li class="chapter" data-level="11.2" data-path="bootstrap.html"><a href="bootstrap.html#bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>11.2</b> Bootstrap Confidence Intervals</a></li>
<li class="chapter" data-level="11.3" data-path="bootstrap.html"><a href="bootstrap.html#bootstrapping-linear-models"><i class="fa fa-check"></i><b>11.3</b> Bootstrapping linear models</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>12</b> Bayesian Statistics</a>
<ul>
<li class="chapter" data-level="12.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#introduction"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-methods-in-general"><i class="fa fa-check"></i><b>12.2</b> Bayesian methods in general</a></li>
<li class="chapter" data-level="12.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-methods-for-a-single-normal-population"><i class="fa fa-check"></i><b>12.3</b> Bayesian methods for a single normal population</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#example"><i class="fa fa-check"></i><b>12.3.1</b> Example</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A First Course in Probability and Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bayesian-statistics" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Chapter 12</span> Bayesian Statistics<a href="bayesian-statistics.html#bayesian-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Introduction<a href="bayesian-statistics.html#introduction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>All of the statistical methods we have discussed so far could be rightly described as “frequentist” in nature. Frequentist statistics, broadly speaking, is concerned with the random behavior of statistics (functions of randomly sampled data) over repeated sampling from the population under study. In frequentist statistics probability is used to describe random behavior induced by random sampling. And, by and large, the effectiveness of frequentist methods—like tests and confidence intervals—is judged by their random behaviors over repeated sampling; e.g., by the type 1 error and power of tests, and the coverage probability of interval estimators.<br><br></p>
<p>In contrast, Bayesian statistics uses probability in two distinct ways: to describe random sampling variability in much the same way as frequentist statistics, and to characterize the uncertainty in unknown parameters. This second use of probability is novel, compared to frequentist statistics (although Bayesian statistics came first chronologically). In frequentist statistics unknown parameters—like the unknown mean <span class="math inline">\(\mu\)</span> of a normal population—are treated as unknown constant variables. In Bayesian statistics, unknown parameters are (mostly) treated as random variables—but, users of Bayesian statistics do not necessarily believe them to be random variables. <br><br></p>
<p>There are some interesting consequences of treating parameters as a random variables. For one, information or assumptions about the parameters apart from the data can be used to assign a <em>prior probability distribution</em> to the parameters, effectively describing their random behavior, or, the beliefs about likely values of those parameters before any data from the population is collected. Second, treating the parameters as random variables allows one to assign probabilities to assertions about the parameters, e.g., <span class="math inline">\(P(\mu \leq 2)\)</span> where <span class="math inline">\(\mu\)</span> is the unknown mean of a normal population under study. In frequentist statistics, no such (non-trivial) probability makes sense. However, the interpretation of such <em>Bayesian</em> probabilities is somewhat unclear—they are not frequentist probabilities describing behavior of the parameter with respect to repeated sampling because the parameter has no random sampling distribution.</p>
</div>
<div id="bayesian-methods-in-general" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> Bayesian methods in general<a href="bayesian-statistics.html#bayesian-methods-in-general" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Bayesian statistics is similar to frequentist likelihood-based inference in that both start with a likelihood describing the sampling distribution of the data, say, <span class="math inline">\(f(x;\theta)\)</span>. For iid data we have <span class="math inline">\(L(\theta) = \prod_{i=1}^n f(x_i;\theta)\)</span> as usual. Bayesian statistics, however, requires an additional ingredient, the prior distribution mentioned above, denoted <span class="math inline">\(\pi(\theta)\)</span>. Recall that the likelihood is the joint distribution of the data given the parameter value <span class="math inline">\(\theta\)</span>. But, now regard the parameter as a random variable, and see that the likelihood is the conditional distribution of the data given the random parameter takes on a certain value. Since the joint distribution of random variables (denoted <span class="math inline">\(g\)</span> below) is equal to the product of their conditional and marginal distributions, we have
<span class="math display">\[g(X_1, \ldots, X_n, \theta) = f(X_1, \ldots, X_n| \theta)\pi(\theta) = L(\theta)\pi(\theta).\]</span>
All Bayesian inference (and prediction) is based on the <em>posterior distribution</em> <span class="math inline">\(\Pi_n(\theta)\)</span>, which is the conditional distribution of the parameter <span class="math inline">\(\theta\)</span> given the observed data, and is derived using Bayes’ Rule:
<span class="math display">\[\Pi_n(\theta) = \frac{L(\theta)\pi(\theta)}{\int L(\vartheta)\pi(\vartheta)d\vartheta }\]</span>
where the denominator is the marginal density of the data, <span class="math inline">\(f(x_1, \ldots, x_n) = \int f(x_1, \ldots, x_n,\vartheta)d\vartheta\)</span>, obtained by integration in the usual manner.
<br><br></p>
<p>If the prior distribution represents what is known (or assumed) about the parameter <strong>before</strong> data is observed, then the posterior distribution represents the up-to-date knowledge (or beliefs) about the parameter <strong>after</strong> data is observed.<br><br></p>
<p>The posterior distribution for a parameter can usually be used to recreate methods analogous to frequentist ones. For example, suppose <span class="math inline">\(\theta\)</span> is a scalar parameter so that <span class="math inline">\(\Pi_n(\theta)\)</span> is a univariate density. We could define a <span class="math inline">\(100(1-\alpha)\%\)</span> <strong>credible interval</strong> for <span class="math inline">\(\theta\)</span> as the interval of values between the <span class="math inline">\(\alpha/2\)</span> and <span class="math inline">\(1-\alpha/2\)</span> quantiles of <span class="math inline">\(\Pi_n(\theta)\)</span>. One might expect that since the Bayesian posterior is based on the likelihood that such an interval would be similar to a confidence interval constructed using a frequentist likelihood-based technique, like a Wald or likelihood ratio-based interval. Usually, that is the case. Hypothesis testing is less straightforward in Bayesian statistics. For example, consider the point null hypothesis <span class="math inline">\(H_0:\mu = \mu_0\)</span> about a normal population mean. The posterior will be a continuous distribution for <span class="math inline">\(\mu\)</span>, and as such, the posterior probability of the null hypothesis will be <span class="math inline">\(P(\mu = \mu_0) = 0\)</span>. Therefore, it wouldn’t make much sense to <strong>accept</strong> null hypotheses with large posterior probabilities, because point nulls will always have zero probability under continuous posteriors. Alternatively, one might define a testing rule in reference to the posterior credible interval above, e.g., reject the null if <span class="math inline">\(\mu_0\)</span> is not in the <span class="math inline">\(100(1-\alpha)\%\)</span> credible interval for some specific choice of <span class="math inline">\(\alpha\)</span>. In many cases, such a test behave similarly to frequentist-based hypothesis tests.</p>
</div>
<div id="bayesian-methods-for-a-single-normal-population" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> Bayesian methods for a single normal population<a href="bayesian-statistics.html#bayesian-methods-for-a-single-normal-population" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose <span class="math inline">\(X_i \stackrel{iid}{\sim}N(\mu, \sigma^2)\)</span>, which represents a normal population with an unknown mean and a known variance. Also, suppose the prior distribution <span class="math inline">\(\pi(\mu)\)</span> is chosen to be <span class="math inline">\(N(\mu_0, \sigma_0^2)\)</span> for known values <span class="math inline">\((\mu_0, \sigma_0^2)\)</span>—these are often called <strong>hyperparameters</strong>.<br><br></p>
<p>The posterior distribution for <span class="math inline">\(\mu\)</span> is proportional to <span class="math inline">\(L(\mu)\pi(\mu)\)</span>, treating the denominator as a proportionality constant. Multiplying the likelihood and prior, we have
<span class="math display">\[\begin{align*}
\Pi_n(\mu)\propto L(\mu)\pi(\mu)\\
&amp; = (2\pi\sigma^2)^{-n/2}(2\pi\sigma_0^2)^{-1/2}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i - \mu)^2 - \frac{1}{2\sigma^2}(\mu - \mu_0)^2\right\}
\end{align*}\]</span>
Look only at the expression in the exponent, and complete the square in <span class="math inline">\(\mu\)</span> to get
<span class="math display">\[\begin{align*}
-\frac{1}{2\sigma^2}&amp;\sum_{x_i - \mu}^2 - \frac{1}{2\sigma_0^2}(\mu - \mu_0)^2\\
&amp; = \mu^2\left[-\frac{n}{2\sigma^2}-\frac{1}{2\sigma_0^2}\right] + \mu\left[\frac{n\bar x}{\sigma^2} + \frac{\mu_0}{\sigma_0^2}\right] - \frac{1}{2\sigma^2}\sum x_i^2 - \frac{\mu_0^2}{2\sigma_0^2}\\
&amp; = -\frac{1}{2\left[\frac{1}{\frac{n}{\sigma^2} + \frac{1}{\sigma_0^2}}\right]}\left(\mu^2 - 2\mu \frac{\frac{n\bar x}{\sigma^2} + \frac{\mu_0}{\sigma_0^2}}{\frac{n}{\sigma^2} + \frac{1}{\sigma_0^2}} - \left[\frac{\frac{n\bar x}{\sigma^2} + \frac{\mu_0}{\sigma_0^2}}{\frac{n}{\sigma^2} + \frac{1}{\sigma_0^2}}\right]^2\right) - \frac{1}{2\sigma^2}\sum x_i^2 - \frac{\mu_0^2}{2\sigma_0^2} - \frac{1}{2}\frac{\left[\frac{n\bar x}{\sigma^2} + \frac{\mu_0}{\sigma_0^2}\right]^2}{\frac{n}{\sigma^2} + \frac{1}{\sigma_0^2}}\\
&amp; =  -\frac{1}{2\left[\frac{1}{\frac{n}{\sigma^2} + \frac{1}{\sigma_0^2}}\right]}\left(\mu - \frac{\frac{n\bar x}{\sigma^2} + \frac{\mu_0}{\sigma_0^2}}{\frac{n}{\sigma^2} + \frac{1}{\sigma_0^2}}\right)^2 + (\text{constants in }\mu).
\end{align*}\]</span>
The above calculation shows that the part of likelihood<span class="math inline">\(\times\)</span>prior depending on <span class="math inline">\(\mu\)</span> appears to be a normal density function. Therefore, since the posterior must be a proper density function (integrating to 1) it follows that
<span class="math display">\[\Pi_n(\mu) \text{ is }N\left(\text{mean }= \frac{\frac{n\bar x}{\sigma^2} + \frac{\mu_0}{\sigma_0^2}}{\frac{n}{\sigma^2} + \frac{1}{\sigma_0^2}}, \,\,\text{variance }=\frac{1}{\frac{n}{\sigma^2} + \frac{1}{\sigma_0^2}}\right).\]</span></p>
<p><br><br></p>
<p>Two remarks about the posterior distribution are quite important. First, notice that the posterior mean may be rewritten as the following weighted average:
<span class="math display">\[\frac{\frac{n\bar x}{\sigma^2} + \frac{\mu_0}{\sigma_0^2}}{\frac{n}{\sigma^2} + \frac{1}{\sigma_0^2}} = \bar x \frac{\frac{\sigma^2}{n\sigma_0^2}}{1+\frac{\sigma^2}{n\sigma_0^2}} + \mu_0\frac{1}{1+\frac{\sigma^2}{n\sigma_0^2}}.\]</span>
And, when <span class="math inline">\(n\)</span> is large, the posterior mean is approximately <span class="math inline">\(\bar x\)</span> because the weight on <span class="math inline">\(\bar x\)</span> approaches 1 while the weight on <span class="math inline">\(\mu_0\)</span> approaches 0. The posterior variance may be rewritten as
<span class="math display">\[\frac{1}{\frac{n}{\sigma^2} + \frac{1}{\sigma_0^2}} = \frac{\sigma^2}{n+\sigma^2/\sigma_0^2}\approx \sigma^2/n\]</span>
where the approximation holds for large <span class="math inline">\(n\)</span>. The upshot is that the posterior is almost the same as the sampling distribution of <span class="math inline">\(\overline X\)</span> when <span class="math inline">\(n\)</span> is large. Consequently, frequentist and Bayesian inferences (e.g. <span class="math inline">\(95\%\)</span> confidence/credible intervals for <span class="math inline">\(\mu\)</span>) will agree when the sample size is large. The second remark is that the posterior distribution turned out to be the same kind of distribution as the prior distribution. The relationship between the prior, likelihood, and posterior in which the prior and posterior are the same type of distribution is called <em>conjugacy</em>. In general, the prior and posterior are only conjugate for certain choices of prior for certain likelihood—conjugacy is the exception, not the rule.</p>
<div id="example" class="section level3 hasAnchor" number="12.3.1">
<h3><span class="header-section-number">12.3.1</span> Example<a href="bayesian-statistics.html#example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A certain transformation of iron levels in water sampled from sites in the Mississippi river is well-modeled by a normal distribution. Previous studies suggest mean iron level around 1.5 (on the transformed scale) with standard deviation 0.05—so the prior distribution is set to be <span class="math inline">\(N(\mu_0 =1.5,\sigma_0^2=0.05^2)\)</span>. 108 iron readings are obtained in a new experiment with a mean of 1.277. Assuming a normal variance of <span class="math inline">\(\sigma^2 = 0.05^2\)</span> the posterior is <span class="math inline">\(N(1.279, 0.05^2/109)\)</span>. The sampling distribution of <span class="math inline">\(\overline X\)</span>, on the other hand, is <span class="math inline">\(N(1.277, 0.05^2/108)\)</span>. The two are plotted below in red and blue, respectively. The <span class="math inline">\(95\%\)</span> confidence interval for <span class="math inline">\(\mu\)</span> is <span class="math inline">\((1.2675,\,1.2864)\)</span> while the corresponding credible interval is <span class="math inline">\((1.2696, \,1.2884)\)</span>.</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="bayesian-statistics.html#cb265-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(SASmixed)</span>
<span id="cb265-2"><a href="bayesian-statistics.html#cb265-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> (Multilocation<span class="sc">$</span>Fe<span class="sc">^</span>{<span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>}<span class="sc">-</span><span class="dv">1</span>)<span class="sc">/</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb265-3"><a href="bayesian-statistics.html#cb265-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(y)</span></code></pre></div>
<p><img src="19-BayesianStatistics_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="bayesian-statistics.html#cb266-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(y)</span></code></pre></div>
<pre><code>## [1] 1.276776</code></pre>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="bayesian-statistics.html#cb268-1" aria-hidden="true" tabindex="-1"></a>dnormx1 <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="fu">dnorm</span>(x, <span class="fl">1.279</span>,<span class="fu">sqrt</span>(<span class="fl">0.05</span><span class="sc">*</span><span class="fl">0.05</span><span class="sc">/</span><span class="dv">109</span>))</span>
<span id="cb268-2"><a href="bayesian-statistics.html#cb268-2" aria-hidden="true" tabindex="-1"></a>dnormx2 <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="fu">dnorm</span>(x, <span class="fl">1.277</span>,<span class="fu">sqrt</span>(<span class="fl">0.05</span><span class="sc">*</span><span class="fl">0.05</span><span class="sc">/</span><span class="dv">108</span>))</span>
<span id="cb268-3"><a href="bayesian-statistics.html#cb268-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb268-4"><a href="bayesian-statistics.html#cb268-4" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(dnormx1, <span class="fl">1.25</span>,<span class="fl">1.3</span>, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>)</span>
<span id="cb268-5"><a href="bayesian-statistics.html#cb268-5" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(dnormx2, <span class="fl">1.25</span>,<span class="fl">1.3</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="19-BayesianStatistics_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bootstrap.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/19-BayesianStatistics.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
