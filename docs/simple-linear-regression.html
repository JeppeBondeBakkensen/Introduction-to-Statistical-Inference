<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Simple Linear Regression | A First Course in Probability and Statistics</title>
  <meta name="description" content="These are a collection of notes related to STAT 588 and 341/342 at Iowa State University. This is a work in progress." />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Simple Linear Regression | A First Course in Probability and Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="These are a collection of notes related to STAT 588 and 341/342 at Iowa State University. This is a work in progress." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Simple Linear Regression | A First Course in Probability and Statistics" />
  
  <meta name="twitter:description" content="These are a collection of notes related to STAT 588 and 341/342 at Iowa State University. This is a work in progress." />
  

<meta name="author" content="Nick Syring" />


<meta name="date" content="2022-10-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="anova.html"/>
<link rel="next" href="multiple-linear-regression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Statistical Inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a></li>
<li class="chapter" data-level="2" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html"><i class="fa fa-check"></i><b>2</b> Data Analysis and Statistical Inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#data-experiments-and-studies"><i class="fa fa-check"></i><b>2.1</b> Data, Experiments, and Studies</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#james-linds-scurvy-trial"><i class="fa fa-check"></i><b>2.1.1</b> James Lind’s Scurvy Trial</a></li>
<li class="chapter" data-level="2.1.2" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#framingham-heart-study"><i class="fa fa-check"></i><b>2.1.2</b> Framingham Heart Study</a></li>
<li class="chapter" data-level="2.1.3" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#harris-bank-sex-pay-study"><i class="fa fa-check"></i><b>2.1.3</b> Harris Bank Sex Pay Study</a></li>
<li class="chapter" data-level="2.1.4" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#large-aggregated-data-sets"><i class="fa fa-check"></i><b>2.1.4</b> Large, Aggregated Data Sets</a></li>
<li class="chapter" data-level="2.1.5" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#study-concepts"><i class="fa fa-check"></i><b>2.1.5</b> Study Concepts</a></li>
<li class="chapter" data-level="2.1.6" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#randomization-control-and-causation"><i class="fa fa-check"></i><b>2.1.6</b> Randomization, control, and causation</a></li>
<li class="chapter" data-level="2.1.7" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#populations-and-scope-of-inference"><i class="fa fa-check"></i><b>2.1.7</b> Populations and scope of inference</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#data-summaries"><i class="fa fa-check"></i><b>2.2</b> Data Summaries</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#numerical-summaries"><i class="fa fa-check"></i><b>2.2.1</b> Numerical Summaries</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#visual-summaries"><i class="fa fa-check"></i><b>2.2.2</b> Visual Summaries</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-analysis-and-statistical-inference.html"><a href="data-analysis-and-statistical-inference.html#statistical-inference"><i class="fa fa-check"></i><b>2.3</b> Statistical Inference</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="statistical-estimation.html"><a href="statistical-estimation.html"><i class="fa fa-check"></i><b>3</b> Statistical Estimation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="statistical-estimation.html"><a href="statistical-estimation.html#vocabulary"><i class="fa fa-check"></i><b>3.1</b> Vocabulary</a></li>
<li class="chapter" data-level="3.2" data-path="statistical-estimation.html"><a href="statistical-estimation.html#properties-of-estimators"><i class="fa fa-check"></i><b>3.2</b> Properties of Estimators</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="statistical-estimation.html"><a href="statistical-estimation.html#bias-and-unbiasedness"><i class="fa fa-check"></i><b>3.2.1</b> Bias and Unbiasedness</a></li>
<li class="chapter" data-level="3.2.2" data-path="statistical-estimation.html"><a href="statistical-estimation.html#minimum-variance-unbiased-estimators"><i class="fa fa-check"></i><b>3.2.2</b> Minimum Variance Unbiased Estimators</a></li>
<li class="chapter" data-level="3.2.3" data-path="statistical-estimation.html"><a href="statistical-estimation.html#mean-squared-error-and-bias-variance-tradeoff"><i class="fa fa-check"></i><b>3.2.3</b> Mean Squared Error and Bias-Variance tradeoff</a></li>
<li class="chapter" data-level="3.2.4" data-path="statistical-estimation.html"><a href="statistical-estimation.html#consistency"><i class="fa fa-check"></i><b>3.2.4</b> Consistency</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="statistical-estimation.html"><a href="statistical-estimation.html#finding-estimators---method-of-moments"><i class="fa fa-check"></i><b>3.3</b> Finding estimators - Method of Moments</a></li>
<li class="chapter" data-level="3.4" data-path="statistical-estimation.html"><a href="statistical-estimation.html#method-of-maximum-likelihood"><i class="fa fa-check"></i><b>3.4</b> Method of Maximum Likelihood</a></li>
<li class="chapter" data-level="3.5" data-path="statistical-estimation.html"><a href="statistical-estimation.html#properties-of-mles"><i class="fa fa-check"></i><b>3.5</b> Properties of MLEs</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>4</b> Sampling Distributions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-mean"><i class="fa fa-check"></i><b>4.1</b> Sample Mean</a></li>
<li class="chapter" data-level="4.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-variance"><i class="fa fa-check"></i><b>4.2</b> Sample Variance</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#large-sample-sampling-distribution-of-sample-variance"><i class="fa fa-check"></i><b>4.2.1</b> Large-sample sampling distribution of sample variance</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sampling-distribution-of-studentized-sample-mean"><i class="fa fa-check"></i><b>4.3</b> Sampling distribution of studentized sample mean</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#part-of-students-theorem---indepndence-of-overline-x_n-and-s_n2"><i class="fa fa-check"></i><b>4.3.1</b> Part of Student’s Theorem - Indepndence of <span class="math inline">\(\overline X_n\)</span> and <span class="math inline">\(S_n^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="sampling-distributions.html"><a href="sampling-distributions.html#differences-of-sample-means"><i class="fa fa-check"></i><b>4.4</b> Differences of Sample Means</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#standarized-difference"><i class="fa fa-check"></i><b>4.4.1</b> Standarized difference</a></li>
<li class="chapter" data-level="4.4.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#studentized-difference-equal-variances"><i class="fa fa-check"></i><b>4.4.2</b> Studentized difference, equal variances</a></li>
<li class="chapter" data-level="4.4.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#studentized-difference-unequal-variances"><i class="fa fa-check"></i><b>4.4.3</b> Studentized difference, unequal variances</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sampling-distributions.html"><a href="sampling-distributions.html#ratios-of-sample-variances"><i class="fa fa-check"></i><b>4.5</b> Ratios of Sample Variances</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>5</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="5.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#why-want-interval-valued-estimates"><i class="fa fa-check"></i><b>5.1</b> Why want interval-valued estimates?</a></li>
<li class="chapter" data-level="5.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#normal-population-mean-example"><i class="fa fa-check"></i><b>5.2</b> Normal population mean example</a></li>
<li class="chapter" data-level="5.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#other-exact-cis-for-normal-population-mean-and-variance-parameters"><i class="fa fa-check"></i><b>5.3</b> Other “Exact” CIs for normal population mean and variance parameters</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#population-mean-unknown-variance"><i class="fa fa-check"></i><b>5.3.1</b> Population mean, unknown variance</a></li>
<li class="chapter" data-level="5.3.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#population-variance-unknown-mean"><i class="fa fa-check"></i><b>5.3.2</b> Population variance, unknown mean</a></li>
<li class="chapter" data-level="5.3.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#two-normal-samples-comparing-means"><i class="fa fa-check"></i><b>5.3.3</b> Two normal samples, comparing means</a></li>
<li class="chapter" data-level="5.3.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#two-normal-samples-comparing-variances"><i class="fa fa-check"></i><b>5.3.4</b> Two normal samples, comparing variances</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#cis-for-proportions"><i class="fa fa-check"></i><b>5.4</b> CIs for proportions</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#a-single-bernoulli-proportion"><i class="fa fa-check"></i><b>5.4.1</b> A single Bernoulli proportion</a></li>
<li class="chapter" data-level="5.4.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#difference-of-two-bernoulli-proportions"><i class="fa fa-check"></i><b>5.4.2</b> Difference of two Bernoulli proportions</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#approximate-cis-based-on-mles"><i class="fa fa-check"></i><b>5.5</b> Approximate CIs based on MLEs</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#multivariate-case"><i class="fa fa-check"></i><b>5.5.1</b> Multivariate case</a></li>
<li class="chapter" data-level="5.5.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#the-delta-method"><i class="fa fa-check"></i><b>5.5.2</b> The Delta method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>6</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#notation"><i class="fa fa-check"></i><b>6.1</b> Notation</a></li>
<li class="chapter" data-level="6.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-outcomes"><i class="fa fa-check"></i><b>6.2</b> Hypothesis testing outcomes</a></li>
<li class="chapter" data-level="6.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#tests-based-on-a-normal-population"><i class="fa fa-check"></i><b>6.3</b> Tests based on a normal population</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-for-a-normal-mean-when-the-variance-is-known"><i class="fa fa-check"></i><b>6.3.1</b> Test for a normal mean when the variance is known</a></li>
<li class="chapter" data-level="6.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-for-a-normal-mean-when-the-variance-is-unknown"><i class="fa fa-check"></i><b>6.3.2</b> Test for a normal mean when the variance is unknown</a></li>
<li class="chapter" data-level="6.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-for-a-normal-population-variance"><i class="fa fa-check"></i><b>6.3.3</b> Test for a normal population variance</a></li>
<li class="chapter" data-level="6.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#example-the-lifetimes-of-infected-guinea-pigs"><i class="fa fa-check"></i><b>6.3.4</b> Example: The lifetimes of infected Guinea pigs</a></li>
<li class="chapter" data-level="6.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#tests-for-a-difference-of-normal-population-means"><i class="fa fa-check"></i><b>6.3.5</b> Tests for a difference of normal population means</a></li>
<li class="chapter" data-level="6.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#test-for-equality-of-normal-population-variances"><i class="fa fa-check"></i><b>6.3.6</b> Test for equality of normal population variances</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#likelihood-based-tests"><i class="fa fa-check"></i><b>6.4</b> Likelihood-based Tests</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wald-type-tests"><i class="fa fa-check"></i><b>6.4.1</b> Wald type tests</a></li>
<li class="chapter" data-level="6.4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#likelihood-ratio-tests"><i class="fa fa-check"></i><b>6.4.2</b> Likelihood ratio tests</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#chi-squared-tests-for-tabulated-data"><i class="fa fa-check"></i><b>6.5</b> Chi Squared tests for tabulated data</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#goodness-of-fit-tests"><i class="fa fa-check"></i><b>6.5.1</b> Goodness of fit tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>7</b> ANOVA</a>
<ul>
<li class="chapter" data-level="7.1" data-path="anova.html"><a href="anova.html#analysis-of-variance"><i class="fa fa-check"></i><b>7.1</b> Analysis of variance</a></li>
<li class="chapter" data-level="7.2" data-path="anova.html"><a href="anova.html#crop-data-in-depth-example"><i class="fa fa-check"></i><b>7.2</b> Crop data in-depth example</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="anova.html"><a href="anova.html#checking-the-equal-variance-assumption"><i class="fa fa-check"></i><b>7.2.1</b> Checking the equal variance assumption</a></li>
<li class="chapter" data-level="7.2.2" data-path="anova.html"><a href="anova.html#normality-and-alternatives-to-the-f-test"><i class="fa fa-check"></i><b>7.2.2</b> Normality and alternatives to the F test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>8</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simple-linear-regression-model"><i class="fa fa-check"></i><b>8.1</b> Simple linear regression model</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#estimation"><i class="fa fa-check"></i><b>8.1.1</b> Estimation</a></li>
<li class="chapter" data-level="8.1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#estimation-of-the-common-variance"><i class="fa fa-check"></i><b>8.1.2</b> Estimation of the common variance</a></li>
<li class="chapter" data-level="8.1.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-for-regression-slope-parameter"><i class="fa fa-check"></i><b>8.1.3</b> Inference for regression slope parameter</a></li>
<li class="chapter" data-level="8.1.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#inference-on-the-conditional-mean-response"><i class="fa fa-check"></i><b>8.1.4</b> Inference on the conditional mean response</a></li>
<li class="chapter" data-level="8.1.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#prediction-of-responses-at-given-x-values"><i class="fa fa-check"></i><b>8.1.5</b> Prediction of responses at given x values</a></li>
<li class="chapter" data-level="8.1.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simultaneous-confidence-bands-for-the-regression-line"><i class="fa fa-check"></i><b>8.1.6</b> Simultaneous confidence bands for the regression line</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#example-house-prices-as-function-of-house-age"><i class="fa fa-check"></i><b>8.2</b> Example: House prices as function of house age</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fitting-the-regression"><i class="fa fa-check"></i><b>8.2.1</b> Fitting the regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>9</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#the-multiple-linear-regression-model"><i class="fa fa-check"></i><b>9.1</b> The Multiple Linear Regression Model</a></li>
<li class="chapter" data-level="9.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#point-estimation"><i class="fa fa-check"></i><b>9.2</b> Point estimation</a></li>
<li class="chapter" data-level="9.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#sampling-distributions-1"><i class="fa fa-check"></i><b>9.3</b> Sampling Distributions</a></li>
<li class="chapter" data-level="9.4" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#inference-on-regression-coefficients"><i class="fa fa-check"></i><b>9.4</b> Inference on regression coefficients</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#example-housing-price-data"><i class="fa fa-check"></i><b>9.4.1</b> Example: Housing price data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="likelihood-based-inferences.html"><a href="likelihood-based-inferences.html"><i class="fa fa-check"></i><b>10</b> Likelihood-Based Inferences</a>
<ul>
<li class="chapter" data-level="10.1" data-path="likelihood-based-inferences.html"><a href="likelihood-based-inferences.html#wald-tests-and-cis"><i class="fa fa-check"></i><b>10.1</b> Wald tests and CIs</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="likelihood-based-inferences.html"><a href="likelihood-based-inferences.html#example-auto-insurance-claims"><i class="fa fa-check"></i><b>10.1.1</b> Example: Auto insurance claims</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A First Course in Probability and Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple-linear-regression" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Simple Linear Regression<a href="simple-linear-regression.html#simple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this chapter we consider estimation and inference of a random response, conditional on another observed variable—the independent variable, also called predictor or covariate. <br><br></p>
<div id="simple-linear-regression-model" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Simple linear regression model<a href="simple-linear-regression.html#simple-linear-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The simple linear regression model says that a random response <span class="math inline">\(Y_i\)</span> has conditional mean <span class="math inline">\(\beta_0 + \beta_1 x_i\)</span> given <span class="math inline">\(X_i = x_i\)</span> where <span class="math inline">\(X_i\)</span> may be a random variable. Moreover, the responses <span class="math inline">\(Y_i\)</span>, <span class="math inline">\(i = 1, \ldots, n\)</span>, are independent, with common variance <span class="math inline">\(\sigma^2\)</span>, and are normally distributed. This is commonly written using the following statistical notation:
<span class="math display">\[Y_i = \beta_0 + \beta_1 x_i + \epsilon_i, \quad \epsilon_i\stackrel{iid}{\sim} N(0, \sigma^2)\]</span>
where <span class="math inline">\(\epsilon_i\)</span> is the “random residual”—what is left over after subtracting the mean from the response. <br><br></p>
<p>The model is “linear” because the mean <span class="math inline">\(E(Y_i|x_i) = \beta_0 + \beta_1 x_i\)</span> is a linear function (a line in two dimensions <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>). The model is “simple” because it is the simplest line (two dimensions). Later we will expand the model by adding covariates, i.e., <span class="math inline">\(x_{1i}, x_{2i}, \ldots\)</span>, to the linear conditional mean function and call it <em>multiple linear regression</em>.</p>
<div id="estimation" class="section level3 hasAnchor" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> Estimation<a href="simple-linear-regression.html#estimation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We estimate <span class="math inline">\((\beta_0, \beta_1)\)</span> simultaneously using the method of “least squares”. The method of least squares defines the line <span class="math inline">\(y = \beta_0 + \beta_1 x\)</span> that is “closest” to the points <span class="math inline">\((y_i, x_i), i=1, \ldots, n\)</span> is the one minimizing the sum of square vertical distances (residuals) from the points to the line:
<span class="math display">\[(\hat\beta_0, \hat\beta_1) = \arg\min_{(\beta_0, \beta_1)}\sum_{i=1}^n(y_i - \beta_0 - \beta_1x_i)^2.\]</span>
The plot below shows these residuals for three points (1.0,1.1), (1.5,2.1), and (2.0,1.8), compared to the line <span class="math inline">\(y=x\)</span>.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="simple-linear-regression.html#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="fl">1.5</span>,<span class="dv">2</span>),<span class="fu">c</span>(<span class="fl">1.1</span>,<span class="fl">2.1</span>,<span class="fl">1.8</span>), <span class="at">xlab =</span> <span class="st">&#39;x&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;y&#39;</span>, <span class="at">main =</span> <span class="st">&#39;&#39;</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">2.5</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">3</span>))</span>
<span id="cb171-2"><a href="simple-linear-regression.html#cb171-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">2.5</span>),<span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">2.5</span>))</span>
<span id="cb171-3"><a href="simple-linear-regression.html#cb171-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="fu">c</span>(<span class="dv">1</span>,<span class="fl">1.1</span>), <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb171-4"><a href="simple-linear-regression.html#cb171-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="fl">1.5</span>,<span class="fl">1.5</span>), <span class="fu">c</span>(<span class="fl">1.5</span>,<span class="fl">2.1</span>), <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb171-5"><a href="simple-linear-regression.html#cb171-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="fu">c</span>(<span class="dv">2</span>,<span class="fl">1.8</span>), <span class="at">lty =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="15-Regression_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>We can determine the estimators <span class="math inline">\((\hat\beta_0, \hat\beta_1)\)</span> by minimizing the sum of squared residuals using calculus:</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial}{\partial\beta_0} \sum_{i=1}^n(y_i - \beta_0 - \beta_1x_i)^2 \\
&amp; = -2\sum_{i=1}^n(y_i - \beta_0 - \beta_1x_i)\\
\text{set  }0 &amp;= -2\sum_{i=1}^n(y_i - \beta_0 - \beta_1x_i)\\
&amp;\Rightarrow \hat\beta_0 = n^{-1}\sum_{i=1}^n(y_i - \beta_1x_i)\\
&amp; = \bar y - \beta_1\bar x
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial}{\partial\beta_1} \sum_{i=1}^n(y_i - \beta_0 - \beta_1x_i)^2 \\
&amp; = -2 \sum_{i=1}^n x_i(y_i - \beta_0 - \beta_1x_i)\\
\text{set  }0 &amp;= -2 \sum_{i=1}^n x_i(y_i - \beta_0 - \beta_1x_i)\\
&amp;\Rightarrow 0 = \sum_{i=1}^n (y_ix_i - x_i(\bar y - \beta_1 \bar x) - \beta_1 x_i^2)\quad \text{by substituting }\beta_0\\
&amp; \beta_1\sum(x_i^2 - x_i\bar x) = \sum_{i=1}^n(y_ix_i - \bar y x_i)\\
&amp;\Rightarrow \hat\beta_1 = \frac{\sum_{i=1}^n (y_ix_i) - n\bar y\bar x}{\sum_{i=1}^n
(x_i^2) - n\bar x^2} = \frac{\sum_{i=1}^n [(y_i - \bar y)(x_i - \bar x)]}{\sum_{i=1}^n (x_i - \bar x)^2}
\end{aligned}
\]</span>
### LSEs are unbiased</p>
<p>A nice property of the least squares method is that it produces unbiased estimators. Consider the expectation <span class="math inline">\(E(\hat\beta_1)\)</span>. Since the <span class="math inline">\(x_i&#39;\)</span>s are non-random, treat these as constants, and find <span class="math inline">\(\hat\beta_1\)</span> is unbiased:</p>
<p><span class="math display">\[
\begin{aligned}
E(\hat\beta_1) &amp; = \frac{\sum_{i=1}^n E((y_i - \bar y))(x_i - \bar x)}{\sum_{i=1}^n (x_i - \bar x)^2}\\
&amp; = \frac{\sum_{i=1}^n (\beta_0 + \beta_1 x_i - n^{-1}\sum_{i=1}^n [\beta_0 +\beta_1 x_i])(x_i - \bar x)}{\sum_{i=1}^n (x_i - \bar x)^2}\\
&amp; = \frac{\beta_1\sum_{i=1}^n ( x_i - \bar x)(x_i - \bar x)}{\sum_{i=1}^n (x_i - \bar x)^2}\\
&amp; = \beta_1.
\end{aligned}
\]</span></p>
<p>Similarly, the estimator of the intercept is unbiased:</p>
<p><span class="math display">\[
\begin{aligned}
E(\hat\beta_0) &amp; = E(\bar y - \hat\beta_1 \bar x)\\
&amp; = n^{-1}\sum_{i=1}^n (\beta_0 + \beta_1x_i) - \beta_1 \bar x\\
&amp; = \beta_0 + \beta_1 \bar x - \beta_1 \bar x\\
&amp; = \beta_0
\end{aligned}
\]</span></p>
</div>
<div id="estimation-of-the-common-variance" class="section level3 hasAnchor" number="8.1.2">
<h3><span class="header-section-number">8.1.2</span> Estimation of the common variance<a href="simple-linear-regression.html#estimation-of-the-common-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Estimating <span class="math inline">\(\sigma^2\)</span> in the regression model is similar to the method used in ANOVA. Define the observed/fitted residuals <span class="math inline">\(\hat e_i = y_i - \hat y_i = y_i - \hat\beta_0 - \hat\beta_1 x_i\)</span>. Since <span class="math inline">\((\hat\beta_0, \hat\beta_1)\)</span> are unbiased, we have <span class="math inline">\(E(\hat e_i) = E(Y_i - \hat\beta_0 - \hat\beta_1 x_i) = 0\)</span>. Therefore, <span class="math inline">\(V(\hat e_i) = E(\hat e_i ^2)\)</span>. And, the method of moments suggests we estimate the variance(in this case second moment) by the sample variance:</p>
<p><span class="math display">\[\hat\sigma^2 = \frac{1}{n-2}\sum_{i=1}^n (y_i - \hat\beta_0 - \hat\beta_1 x_i)^2,\]</span>
where we divide by <span class="math inline">\(n-2\)</span> so that the resulting estimator is unbiased. (I’ll leave that as a challenging exercise for the reader).</p>
</div>
<div id="inference-for-regression-slope-parameter" class="section level3 hasAnchor" number="8.1.3">
<h3><span class="header-section-number">8.1.3</span> Inference for regression slope parameter<a href="simple-linear-regression.html#inference-for-regression-slope-parameter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are two main inference (and prediction) problems of interest in regression. The first is inference on <span class="math inline">\(\beta_1\)</span>, and, in particular, testing <span class="math inline">\(\beta_1 = 0\)</span>. If <span class="math inline">\(\beta_1=0\)</span> then there is no linear relationship between the covariate <span class="math inline">\(x\)</span> and the response <span class="math inline">\(Y\)</span>, and <span class="math inline">\(Y\)</span> has a constant mean (so is iid, rather than independent). Testing <span class="math inline">\(\beta_1=0\)</span> is similar to the ANOVA F test for categorical <span class="math inline">\(x\)</span>, rather than continuous <span class="math inline">\(x\)</span> in regression.<br />
<br><br></p>
<p>For inference on <span class="math inline">\(\beta_1\)</span> we need the sampling distribution of <span class="math inline">\(\hat\beta_1\)</span>. Recognize that we can write this estimator as
<span class="math display">\[\hat\beta_1 = \frac{\sum_{i=1}^n Y_i(x_i - \bar x)}{\sum_{i=1}^n (x_i - \bar x)^2}\]</span> because <span class="math inline">\(\sum_{i=1}^n \bar Y(x_i - \bar x) = 0\)</span>. Then, we see that <span class="math inline">\(\hat\beta_1\)</span> is a linear combination of <span class="math inline">\(Y_i\)</span>, i.e., <span class="math inline">\(\hat\beta_1 = \sum_{i=1}^nc_i Y_i\)</span> for non-random <span class="math inline">\(c_i\)</span>. By a MGF argument we have used before, linear combinations of normal random variables are also normally-distributed. This means,
<span class="math display">\[\hat\beta_1 \sim N\left(\beta_1, \sigma_2\sum_{i=1}^n c_i^2\right).\]</span></p>
<p>Furthermore, by essentially the same argument as in the proof of Student’s Theorem,
<span class="math display">\[\frac{(n-2)\hat\sigma^2}{\sigma^2}\sim \chi^2(n-2)\]</span>
so that the studentized slope estimator has a Student’s <span class="math inline">\(t\)</span> distribution:
<span class="math display">\[t = \frac{\hat\beta_1 - \beta_1}{\sqrt{\hat\sigma^2 \left[\sum_{i=1}^n (x_i - \bar x)^2\right]^{-1}}}\sim t_{n-2}\]</span></p>
<p><br></p>
<p>A test of <span class="math inline">\(H_0:\beta_1 = b\)</span> versus <span class="math inline">\(H_a:\beta_1 \ne b\)</span> rejects the null if
<span class="math display">\[\frac{|\hat\beta_1 - b|}{\sqrt{\hat\sigma^2 \left[\sum_{i=1}^n (x_i - \bar x)^2\right]^{-1}}} &gt; t_{1-\alpha/2, n-2}\]</span></p>
<p>Similarly, a <span class="math inline">\(100(1-\alpha)\%\)</span> CI for <span class="math inline">\(\beta_1\)</span> is given by
<span class="math display">\[\left(\hat\beta_1 \pm t_{1-\alpha/2, n-2}\sqrt{\hat\sigma^2 \left[\sum_{i=1}^n (x_i - \bar x)^2\right]^{-1}}\right).\]</span></p>
</div>
<div id="inference-on-the-conditional-mean-response" class="section level3 hasAnchor" number="8.1.4">
<h3><span class="header-section-number">8.1.4</span> Inference on the conditional mean response<a href="simple-linear-regression.html#inference-on-the-conditional-mean-response" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Besides testing for <span class="math inline">\(H_0:\beta_1 = 0\)</span>, which means that the covariate has no effect on the mean response, experimenters often want to make inferences about the conditional mean response at a particular covariate value <span class="math inline">\(x\)</span>. As we showed above, <span class="math inline">\(\hat\beta_0 + \hat\beta_1 x\)</span> is unbiased for <span class="math inline">\(E(Y|x) = \beta_0 + \beta_1 x\)</span>. Furthermore, the variance of the estimator of the conditional mean is as follows:</p>
<p><span class="math display">\[\begin{align*}
V(\hat\beta_0 + \hat\beta_1 x) &amp;= V(\overline Y - \hat\beta_1 \overline x + \hat\beta_1 x) \\
&amp; = V\left(\overline Y + (x - \overline x)\frac{\sum Y_i(x_i - \overline x)}{\sum (x_i - \overline x)^2}\right)\\
&amp; = V\left( \sum Y_i \left(n^{-1} + (x - \overline x)\frac{(x_i - \overline x)}{\sum (x_i - \overline x)^2}\right)\right)\\
&amp; = \sum_{i=1}^n V\left(Y_i\left(n^{-1} + (x - \overline x)\frac{(x_i - \overline x)}{\sum (x_i - \overline x)^2}\right)\right)\\
&amp; = \sigma^2\sum_{i=1}^n \frac{1}{n^2} + \frac{(x - \overline x)^2(x_i - \overline x)^2}{\left[\sum (x_i - \overline x)^2\right]^2}\\
&amp; = \sigma^2\left(n^{-1} + \frac{(x - \overline x)^2}{\sum (x_i - \overline x)^2}\right)
\end{align*}\]</span></p>
<p>Replacing the unknown variance <span class="math inline">\(\sigma^2\)</span> by its estimator (the MSE) we obtain a Student’s <span class="math inline">\(t\)</span> random variable with <span class="math inline">\(n-2\)</span> degrees of freedom:
<span class="math display">\[t = \frac{\hat\beta_0 + \hat\beta_1 x  - (\beta_0 + \beta_1 x)}{\sqrt{MSE \left(n^{-1} + \frac{(x - \overline x)^2}{\sum (x_i - \overline x)^2}\right)}}\sim t_{n-2}.\]</span></p>
<p>This may be used to define a confidence interval for the conditional mean response at a given covariate value <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[\left(\hat\beta_0 + \hat\beta_1 x \pm t_{1-\alpha/2, n-2}\sqrt{MSE \left(n^{-1} + \frac{(x - \overline x)^2}{\sum (x_i - \overline x)^2}\right)}  \right)\]</span></p>
</div>
<div id="prediction-of-responses-at-given-x-values" class="section level3 hasAnchor" number="8.1.5">
<h3><span class="header-section-number">8.1.5</span> Prediction of responses at given x values<a href="simple-linear-regression.html#prediction-of-responses-at-given-x-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(Y^\star\)</span> denote a future response for a given covariate value <span class="math inline">\(x\)</span>. We want to predict <span class="math inline">\(Y^\star\sim N(\beta_0 + \beta_1 x, \sigma^2)\)</span>. Now, we can represent <span class="math inline">\(Y^\star\)</span> using the regression model as
<span class="math display">\[Y^\star = \beta_0 + \beta_1 x + \epsilon^\star\]</span>
for a future random residual <span class="math inline">\(\epsilon^\star\)</span>. An unbiased point prediction of <span class="math inline">\(Y^\star\)</span> is given by the estimate of its mean <span class="math inline">\(\hat\beta_0 + \hat\beta_1 x\)</span>. The variance of the point prediction is
<span class="math display">\[V(\hat{Y^\star}) = V(\hat\beta_0 + \hat\beta_1 x + \epsilon^\star) = \sigma^2\left(1 +n^{-1} + \frac{(x - \overline x)^2}{\sum (x_i - \overline x)^2}\right).\]</span></p>
<p>Therefore, a <span class="math inline">\(100(1-\alpha)\%\)</span> prediction interval for <span class="math inline">\(Y^\star\)</span> is given by
<span class="math display">\[\left(\hat\beta_0 + \hat\beta_1 x \pm t_{1-\alpha/2, n-2}\sqrt{MSE \left(1 +n^{-1} + \frac{(x - \overline x)^2}{\sum (x_i - \overline x)^2}\right)}  \right).\]</span></p>
<p>Prediction intervals have interpretations similar to confidence intervals. If the model is true, a <span class="math inline">\(95\%\)</span> prediction interval for <span class="math inline">\(Y^\star\)</span> at a given <span class="math inline">\(x\)</span> has the following property: suppose we repeat a regression experiment many, many times. Each time we compute a <span class="math inline">\(95\%\)</span> interval and then observe a new response <span class="math inline">\(Y^\star\)</span>. then, about <span class="math inline">\(95\%\)</span> of the time, our computed prediction interval contains that realized <span class="math inline">\(Y^\star\)</span>. This is easiest to see given a simulation experiment.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="simple-linear-regression.html#cb172-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>  <span class="co"># covariate values are 1, 2, 3, 4, 5, 6, 7, 8, 9, 10</span></span>
<span id="cb172-2"><a href="simple-linear-regression.html#cb172-2" aria-hidden="true" tabindex="-1"></a>cover <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>,<span class="dv">1000</span>) <span class="co"># record whether the prediction interval contains the new response Y*</span></span>
<span id="cb172-3"><a href="simple-linear-regression.html#cb172-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(r <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>){  <span class="co"># loop 1000 &quot;experiments&quot;</span></span>
<span id="cb172-4"><a href="simple-linear-regression.html#cb172-4" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10</span>,<span class="dv">1</span><span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>x)  <span class="co"># randomly sample the responses </span></span>
<span id="cb172-5"><a href="simple-linear-regression.html#cb172-5" aria-hidden="true" tabindex="-1"></a>my.lm <span class="ot">&lt;-</span> <span class="fu">summary</span>(<span class="fu">lm</span>(Y<span class="sc">~</span>x))  <span class="co"># compute the point estimates of beta0, beta1 and sigma^2</span></span>
<span id="cb172-6"><a href="simple-linear-regression.html#cb172-6" aria-hidden="true" tabindex="-1"></a>MSE <span class="ot">&lt;-</span> <span class="fu">sum</span>(my.lm<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">8</span> <span class="co"># point estimate of sigma^2</span></span>
<span id="cb172-7"><a href="simple-linear-regression.html#cb172-7" aria-hidden="true" tabindex="-1"></a>beta0.hat <span class="ot">&lt;-</span> my.lm<span class="sc">$</span>coefficients[<span class="dv">1</span>] <span class="co"># storing the estimates of beta0 and beta 1</span></span>
<span id="cb172-8"><a href="simple-linear-regression.html#cb172-8" aria-hidden="true" tabindex="-1"></a>beta1.hat <span class="ot">&lt;-</span> my.lm<span class="sc">$</span>coefficients[<span class="dv">2</span>]</span>
<span id="cb172-9"><a href="simple-linear-regression.html#cb172-9" aria-hidden="true" tabindex="-1"></a>mean.hat <span class="ot">&lt;-</span> beta0.hat <span class="sc">+</span> beta1.hat<span class="sc">*</span><span class="dv">4</span> <span class="co"># the estimated conditional mean response</span></span>
<span id="cb172-10"><a href="simple-linear-regression.html#cb172-10" aria-hidden="true" tabindex="-1"></a>se.term <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">+</span><span class="dv">1</span><span class="sc">/</span><span class="dv">10</span> <span class="sc">+</span> ((<span class="dv">4</span><span class="sc">-</span><span class="fu">mean</span>(x))<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (<span class="fu">sum</span>((x<span class="sc">-</span><span class="fu">mean</span>(x))<span class="sc">^</span><span class="dv">2</span>))) <span class="co"># the 1 + 1/n + (x-xbar)^2/sum(xi - xbar)^2 term in the standard error</span></span>
<span id="cb172-11"><a href="simple-linear-regression.html#cb172-11" aria-hidden="true" tabindex="-1"></a>my.PI <span class="ot">&lt;-</span> <span class="fu">c</span>(mean.hat <span class="sc">+</span> <span class="fu">qt</span>(<span class="fl">0.025</span>,<span class="dv">8</span>)<span class="sc">*</span><span class="fu">sqrt</span>(MSE<span class="sc">*</span>se.term), mean.hat <span class="sc">+</span> <span class="fu">qt</span>(<span class="fl">0.975</span>,<span class="dv">8</span>)<span class="sc">*</span><span class="fu">sqrt</span>(MSE<span class="sc">*</span>se.term)) <span class="co"># prediction intervals</span></span>
<span id="cb172-12"><a href="simple-linear-regression.html#cb172-12" aria-hidden="true" tabindex="-1"></a>Y.star <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>,<span class="dv">1</span><span class="sc">+</span><span class="dv">2</span><span class="sc">*</span><span class="dv">4</span>) <span class="co"># sample a new response Y*</span></span>
<span id="cb172-13"><a href="simple-linear-regression.html#cb172-13" aria-hidden="true" tabindex="-1"></a>cover[r] <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(my.PI[<span class="dv">1</span>] <span class="sc">&lt;</span> Y.star <span class="sc">&amp;</span> my.PI[<span class="dv">2</span>] <span class="sc">&gt;</span> Y.star, <span class="dv">1</span>, <span class="dv">0</span>) <span class="co"># check if interval contains (&quot;covers&quot;) the Y*</span></span>
<span id="cb172-14"><a href="simple-linear-regression.html#cb172-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb172-15"><a href="simple-linear-regression.html#cb172-15" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(cover)  <span class="co"># realized coverage proportion, should be about 95%</span></span></code></pre></div>
<pre><code>## [1] 0.941</code></pre>
</div>
<div id="simultaneous-confidence-bands-for-the-regression-line" class="section level3 hasAnchor" number="8.1.6">
<h3><span class="header-section-number">8.1.6</span> Simultaneous confidence bands for the regression line<a href="simple-linear-regression.html#simultaneous-confidence-bands-for-the-regression-line" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If experimenters want to quantify uncertainty about the entire regression line, then we may compute simultaneous confidence bands. The interpretation of these bands is similar to the interpretation of a confidence interval for a ream response at a given <span class="math inline">\(x\)</span>, except the object we are claiming to capture by the bands is the line itself, rather than a point on the line. <br><br></p>
<p>We may construct such bands based on simultaneous confidence intervals for the two parameters the line depends on, which are <span class="math inline">\((\beta_0, \beta_1)\)</span>. By <em>simultaneous</em>, we mean a confidence set (in two dimensions) that has probability <span class="math inline">\(100(1-\alpha)\%\)</span> to capture the point <span class="math inline">\((\beta_0, \beta_1)\)</span> with respect to repeated experimentation/random sampling.<br><br></p>
<p>The Scheffe method may be used to construct simultaneous CIs for <span class="math inline">\((\beta_0, \beta_1)\)</span>. The Scheffe simultaneous CIs are given by
<span class="math display">\[\left(\hat\beta_0 \pm \sqrt{\frac{2F_{1-\alpha, 2, n-2}MSE n^{-1}\sum x_i^2}{\sum(x_i - \overline x)^2}}\right),\]</span>
and
<span class="math display">\[\left(\hat\beta_1 \pm \sqrt{\frac{2F_{1-\alpha, 2, n-2}MSE }{\sum(x_i - \overline x)^2}}\right).\]</span></p>
<p>A simultaneous confidence band for <span class="math inline">\(\beta_0 + \beta_1 x\)</span> over <span class="math inline">\(x \in (a,b)\)</span> has lower bound <span class="math inline">\(b_0 + b_1 x\)</span> and upper bound <span class="math inline">\(B_0 +B_1 x\)</span> where <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are the lower bounds of the simultaneous CIs of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(B_0\)</span> and <span class="math inline">\(B_1\)</span> are the upper bounds.</p>
</div>
</div>
<div id="example-house-prices-as-function-of-house-age" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Example: House prices as function of house age<a href="simple-linear-regression.html#example-house-prices-as-function-of-house-age" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<a href="data:text/csv;base64,No,X1 transaction date,X2 house age,X3 distance to the nearest MRT station,X4 number of convenience stores,X5 latitude,X6 longitude,Y house price of unit area
1,2012.917,32,84.87882,10,24.98298,121.54024,37.9
2,2012.917,19.5,306.5947,9,24.98034,121.53951,42.2
3,2013.583,13.3,561.9845,5,24.98746,121.54391,47.3
4,2013.500,13.3,561.9845,5,24.98746,121.54391,54.8
5,2012.833,5,390.5684,5,24.97937,121.54245,43.1
6,2012.667,7.1,2175.03,3,24.96305,121.51254,32.1
7,2012.667,34.5,623.4731,7,24.97933,121.53642,40.3
8,2013.417,20.3,287.6025,6,24.98042,121.54228,46.7
9,2013.500,31.7,5512.038,1,24.95095,121.48458,18.8
10,2013.417,17.9,1783.18,3,24.96731,121.51486,22.1
11,2013.083,34.8,405.2134,1,24.97349,121.53372,41.4
12,2013.333,6.3,90.45606,9,24.97433,121.5431,58.1
13,2012.917,13,492.2313,5,24.96515,121.53737,39.3
14,2012.667,20.4,2469.645,4,24.96108,121.51046,23.8
15,2013.500,13.2,1164.838,4,24.99156,121.53406,34.3
16,2013.583,35.7,579.2083,2,24.9824,121.54619,50.5
17,2013.250,0,292.9978,6,24.97744,121.54458,70.1
18,2012.750,17.7,350.8515,1,24.97544,121.53119,37.4
19,2013.417,16.9,368.1363,8,24.9675,121.54451,42.3
20,2012.667,1.5,23.38284,7,24.96772,121.54102,47.7
21,2013.417,4.5,2275.877,3,24.96314,121.51151,29.3
22,2013.417,10.5,279.1726,7,24.97528,121.54541,51.6
23,2012.917,14.7,1360.139,1,24.95204,121.54842,24.6
24,2013.083,10.1,279.1726,7,24.97528,121.54541,47.9
25,2013.000,39.6,480.6977,4,24.97353,121.53885,38.8
26,2013.083,29.3,1487.868,2,24.97542,121.51726,27
27,2012.667,3.1,383.8624,5,24.98085,121.54391,56.2
28,2013.250,10.4,276.449,5,24.95593,121.53913,33.6
29,2013.500,19.2,557.478,4,24.97419,121.53797,47
30,2013.083,7.1,451.2438,5,24.97563,121.54694,57.1
31,2013.500,25.9,4519.69,0,24.94826,121.49587,22.1
32,2012.750,29.6,769.4034,7,24.98281,121.53408,25
33,2012.750,37.9,488.5727,1,24.97349,121.53451,34.2
34,2013.250,16.5,323.655,6,24.97841,121.54281,49.3
35,2012.750,15.4,205.367,7,24.98419,121.54243,55.1
36,2013.500,13.9,4079.418,0,25.01459,121.51816,27.3
37,2012.917,14.7,1935.009,2,24.96386,121.51458,22.9
38,2013.167,12,1360.139,1,24.95204,121.54842,25.3
39,2012.667,3.1,577.9615,6,24.97201,121.54722,47.7
40,2013.167,16.2,289.3248,5,24.98203,121.54348,46.2
41,2013.000,13.6,4082.015,0,24.94155,121.50381,15.9
42,2013.500,16.8,4066.587,0,24.94297,121.50342,18.2
43,2013.417,36.1,519.4617,5,24.96305,121.53758,34.7
44,2012.750,34.4,512.7871,6,24.98748,121.54301,34.1
45,2013.583,2.7,533.4762,4,24.97445,121.54765,53.9
46,2013.083,36.6,488.8193,8,24.97015,121.54494,38.3
47,2013.417,21.7,463.9623,9,24.9703,121.54458,42
48,2013.583,35.9,640.7391,3,24.97563,121.53715,61.5
49,2013.417,24.2,4605.749,0,24.94684,121.49578,13.4
50,2012.667,29.4,4510.359,1,24.94925,121.49542,13.2
51,2013.417,21.7,512.5487,4,24.974,121.53842,44.2
52,2013.083,31.3,1758.406,1,24.95402,121.55282,20.7
53,2013.583,32.1,1438.579,3,24.97419,121.5175,27
54,2013.083,13.3,492.2313,5,24.96515,121.53737,38.9
55,2013.083,16.1,289.3248,5,24.98203,121.54348,51.7
56,2012.833,31.7,1160.632,0,24.94968,121.53009,13.7
57,2013.417,33.6,371.2495,8,24.97254,121.54059,41.9
58,2012.917,3.5,56.47425,7,24.95744,121.53711,53.5
59,2013.500,30.3,4510.359,1,24.94925,121.49542,22.6
60,2013.083,13.3,336.0532,5,24.95776,121.53438,42.4
61,2013.417,11,1931.207,2,24.96365,121.51471,21.3
62,2013.500,5.3,259.6607,6,24.97585,121.54516,63.2
63,2012.917,17.2,2175.877,3,24.96303,121.51254,27.7
64,2013.583,2.6,533.4762,4,24.97445,121.54765,55
65,2013.333,17.5,995.7554,0,24.96305,121.54915,25.3
66,2013.417,40.1,123.7429,8,24.97635,121.54329,44.3
67,2013.000,1,193.5845,6,24.96571,121.54089,50.7
68,2013.500,8.5,104.8101,5,24.96674,121.54067,56.8
69,2013.417,30.4,464.223,6,24.97964,121.53805,36.2
70,2012.833,12.5,561.9845,5,24.98746,121.54391,42
71,2013.583,6.6,90.45606,9,24.97433,121.5431,59
72,2013.083,35.5,640.7391,3,24.97563,121.53715,40.8
73,2013.583,32.5,424.5442,8,24.97587,121.53913,36.3
74,2013.167,13.8,4082.015,0,24.94155,121.50381,20
75,2012.917,6.8,379.5575,10,24.98343,121.53762,54.4
76,2013.500,12.3,1360.139,1,24.95204,121.54842,29.5
77,2013.583,35.9,616.4004,3,24.97723,121.53767,36.8
78,2012.833,20.5,2185.128,3,24.96322,121.51237,25.6
79,2012.917,38.2,552.4371,2,24.97598,121.53381,29.8
80,2013.000,18,1414.837,1,24.95182,121.54887,26.5
81,2013.500,11.8,533.4762,4,24.97445,121.54765,40.3
82,2013.000,30.8,377.7956,6,24.96427,121.53964,36.8
83,2013.083,13.2,150.9347,7,24.96725,121.54252,48.1
84,2012.917,25.3,2707.392,3,24.96056,121.50831,17.7
85,2013.083,15.1,383.2805,7,24.96735,121.54464,43.7
86,2012.750,0,338.9679,9,24.96853,121.54413,50.8
87,2012.833,1.8,1455.798,1,24.9512,121.549,27
88,2013.583,16.9,4066.587,0,24.94297,121.50342,18.3
89,2012.917,8.9,1406.43,0,24.98573,121.52758,48
90,2013.500,23,3947.945,0,24.94783,121.50243,25.3
91,2012.833,0,274.0144,1,24.9748,121.53059,45.4
92,2013.250,9.1,1402.016,0,24.98569,121.5276,43.2
93,2012.917,20.6,2469.645,4,24.96108,121.51046,21.8
94,2012.917,31.9,1146.329,0,24.9492,121.53076,16.1
95,2012.917,40.9,167.5989,5,24.9663,121.54026,41
96,2012.917,8,104.8101,5,24.96674,121.54067,51.8
97,2013.417,6.4,90.45606,9,24.97433,121.5431,59.5
98,2013.083,28.4,617.4424,3,24.97746,121.53299,34.6
99,2013.417,16.4,289.3248,5,24.98203,121.54348,51
100,2013.417,6.4,90.45606,9,24.97433,121.5431,62.2
101,2013.500,17.5,964.7496,4,24.98872,121.53411,38.2
102,2012.833,12.7,170.1289,1,24.97371,121.52984,32.9
103,2013.083,1.1,193.5845,6,24.96571,121.54089,54.4
104,2012.750,0,208.3905,6,24.95618,121.53844,45.7
105,2012.667,32.7,392.4459,6,24.96398,121.5425,30.5
106,2012.833,0,292.9978,6,24.97744,121.54458,71
107,2013.083,17.2,189.5181,8,24.97707,121.54308,47.1
108,2013.333,12.2,1360.139,1,24.95204,121.54842,26.6
109,2013.417,31.4,592.5006,2,24.9726,121.53561,34.1
110,2013.583,4,2147.376,3,24.96299,121.51284,28.4
111,2013.083,8.1,104.8101,5,24.96674,121.54067,51.6
112,2013.583,33.3,196.6172,7,24.97701,121.54224,39.4
113,2013.417,9.9,2102.427,3,24.96044,121.51462,23.1
114,2013.333,14.8,393.2606,6,24.96172,121.53812,7.6
115,2012.667,30.6,143.8383,8,24.98155,121.54142,53.3
116,2013.083,20.6,737.9161,2,24.98092,121.54739,46.4
117,2013.000,30.9,6396.283,1,24.94375,121.47883,12.2
118,2013.000,13.6,4197.349,0,24.93885,121.50383,13
119,2013.500,25.3,1583.722,3,24.96622,121.51709,30.6
120,2013.500,16.6,289.3248,5,24.98203,121.54348,59.6
121,2013.167,13.3,492.2313,5,24.96515,121.53737,31.3
122,2013.500,13.6,492.2313,5,24.96515,121.53737,48
123,2013.250,31.5,414.9476,4,24.98199,121.54464,32.5
124,2013.417,0,185.4296,0,24.9711,121.5317,45.5
125,2012.917,9.9,279.1726,7,24.97528,121.54541,57.4
126,2013.167,1.1,193.5845,6,24.96571,121.54089,48.6
127,2013.083,38.6,804.6897,4,24.97838,121.53477,62.9
128,2013.250,3.8,383.8624,5,24.98085,121.54391,55
129,2013.083,41.3,124.9912,6,24.96674,121.54039,60.7
130,2013.417,38.5,216.8329,7,24.98086,121.54162,41
131,2013.250,29.6,535.527,8,24.98092,121.53653,37.5
132,2013.500,4,2147.376,3,24.96299,121.51284,30.7
133,2013.167,26.6,482.7581,5,24.97433,121.53863,37.5
134,2012.833,18,373.3937,8,24.9866,121.54082,39.5
135,2012.667,33.4,186.9686,6,24.96604,121.54211,42.2
136,2012.917,18.9,1009.235,0,24.96357,121.54951,20.8
137,2012.750,11.4,390.5684,5,24.97937,121.54245,46.8
138,2013.500,13.6,319.0708,6,24.96495,121.54277,47.4
139,2013.167,10,942.4664,0,24.97843,121.52406,43.5
140,2012.667,12.9,492.2313,5,24.96515,121.53737,42.5
141,2013.250,16.2,289.3248,5,24.98203,121.54348,51.4
142,2013.333,5.1,1559.827,3,24.97213,121.51627,28.9
143,2013.417,19.8,640.6071,5,24.97017,121.54647,37.5
144,2013.500,13.6,492.2313,5,24.96515,121.53737,40.1
145,2013.083,11.9,1360.139,1,24.95204,121.54842,28.4
146,2012.917,2.1,451.2438,5,24.97563,121.54694,45.5
147,2012.750,0,185.4296,0,24.9711,121.5317,52.2
148,2012.750,3.2,489.8821,8,24.97017,121.54494,43.2
149,2013.500,16.4,3780.59,0,24.93293,121.51203,45.1
150,2012.667,34.9,179.4538,8,24.97349,121.54245,39.7
151,2013.250,35.8,170.7311,7,24.96719,121.54269,48.5
152,2013.500,4.9,387.7721,9,24.98118,121.53788,44.7
153,2013.333,12,1360.139,1,24.95204,121.54842,28.9
154,2013.250,6.5,376.1709,6,24.95418,121.53713,40.9
155,2013.500,16.9,4066.587,0,24.94297,121.50342,20.7
156,2013.167,13.8,4082.015,0,24.94155,121.50381,15.6
157,2013.583,30.7,1264.73,0,24.94883,121.52954,18.3
158,2013.250,16.1,815.9314,4,24.97886,121.53464,35.6
159,2013.000,11.6,390.5684,5,24.97937,121.54245,39.4
160,2012.667,15.5,815.9314,4,24.97886,121.53464,37.4
161,2012.917,3.5,49.66105,8,24.95836,121.53756,57.8
162,2013.417,19.2,616.4004,3,24.97723,121.53767,39.6
163,2012.750,16,4066.587,0,24.94297,121.50342,11.6
164,2013.500,8.5,104.8101,5,24.96674,121.54067,55.5
165,2012.833,0,185.4296,0,24.9711,121.5317,55.2
166,2012.917,13.7,1236.564,1,24.97694,121.55391,30.6
167,2013.417,0,292.9978,6,24.97744,121.54458,73.6
168,2013.417,28.2,330.0854,8,24.97408,121.54011,43.4
169,2013.083,27.6,515.1122,5,24.96299,121.5432,37.4
170,2013.417,8.4,1962.628,1,24.95468,121.55481,23.5
171,2013.333,24,4527.687,0,24.94741,121.49628,14.4
172,2013.083,3.6,383.8624,5,24.98085,121.54391,58.8
173,2013.583,6.6,90.45606,9,24.97433,121.5431,58.1
174,2013.083,41.3,401.8807,4,24.98326,121.5446,35.1
175,2013.417,4.3,432.0385,7,24.9805,121.53778,45.2
176,2013.083,30.2,472.1745,3,24.97005,121.53758,36.5
177,2012.833,13.9,4573.779,0,24.94867,121.49507,19.2
178,2013.083,33,181.0766,9,24.97697,121.54262,42
179,2013.500,13.1,1144.436,4,24.99176,121.53456,36.7
180,2013.083,14,438.8513,1,24.97493,121.5273,42.6
181,2012.667,26.9,4449.27,0,24.94898,121.49621,15.5
182,2013.167,11.6,201.8939,8,24.98489,121.54121,55.9
183,2013.500,13.5,2147.376,3,24.96299,121.51284,23.6
184,2013.500,17,4082.015,0,24.94155,121.50381,18.8
185,2012.750,14.1,2615.465,0,24.95495,121.56174,21.8
186,2012.750,31.4,1447.286,3,24.97285,121.5173,21.5
187,2013.167,20.9,2185.128,3,24.96322,121.51237,25.7
188,2013.000,8.9,3078.176,0,24.95464,121.56627,22
189,2012.917,34.8,190.0392,8,24.97707,121.54312,44.3
190,2012.917,16.3,4066.587,0,24.94297,121.50342,20.5
191,2013.500,35.3,616.5735,8,24.97945,121.53642,42.3
192,2013.167,13.2,750.0704,2,24.97371,121.54951,37.8
193,2013.167,43.8,57.58945,7,24.9675,121.54069,42.7
194,2013.417,9.7,421.479,5,24.98246,121.54477,49.3
195,2013.500,15.2,3771.895,0,24.93363,121.51158,29.3
196,2013.333,15.2,461.1016,5,24.95425,121.5399,34.6
197,2013.000,22.8,707.9067,2,24.981,121.54713,36.6
198,2013.250,34.4,126.7286,8,24.96881,121.54089,48.2
199,2013.083,34,157.6052,7,24.96628,121.54196,39.1
200,2013.417,18.2,451.6419,8,24.96945,121.5449,31.6
201,2013.417,17.4,995.7554,0,24.96305,121.54915,25.5
202,2013.417,13.1,561.9845,5,24.98746,121.54391,45.9
203,2012.917,38.3,642.6985,3,24.97559,121.53713,31.5
204,2012.667,15.6,289.3248,5,24.98203,121.54348,46.1
205,2013.000,18,1414.837,1,24.95182,121.54887,26.6
206,2013.083,12.8,1449.722,3,24.97289,121.51728,21.4
207,2013.250,22.2,379.5575,10,24.98343,121.53762,44
208,2013.083,38.5,665.0636,3,24.97503,121.53692,34.2
209,2012.750,11.5,1360.139,1,24.95204,121.54842,26.2
210,2012.833,34.8,175.6294,8,24.97347,121.54271,40.9
211,2013.500,5.2,390.5684,5,24.97937,121.54245,52.2
212,2013.083,0,274.0144,1,24.9748,121.53059,43.5
213,2013.333,17.6,1805.665,2,24.98672,121.52091,31.1
214,2013.083,6.2,90.45606,9,24.97433,121.5431,58
215,2013.583,18.1,1783.18,3,24.96731,121.51486,20.9
216,2013.333,19.2,383.7129,8,24.972,121.54477,48.1
217,2013.250,37.8,590.9292,1,24.97153,121.53559,39.7
218,2012.917,28,372.6242,6,24.97838,121.54119,40.8
219,2013.417,13.6,492.2313,5,24.96515,121.53737,43.8
220,2012.750,29.3,529.7771,8,24.98102,121.53655,40.2
221,2013.333,37.2,186.5101,9,24.97703,121.54265,78.3
222,2013.333,9,1402.016,0,24.98569,121.5276,38.5
223,2013.583,30.6,431.1114,10,24.98123,121.53743,48.5
224,2013.250,9.1,1402.016,0,24.98569,121.5276,42.3
225,2013.333,34.5,324.9419,6,24.97814,121.5417,46
226,2013.250,1.1,193.5845,6,24.96571,121.54089,49
227,2013.000,16.5,4082.015,0,24.94155,121.50381,12.8
228,2012.917,32.4,265.0609,8,24.98059,121.53986,40.2
229,2013.417,11.9,3171.329,0,25.00115,121.51776,46.6
230,2013.583,31,1156.412,0,24.9489,121.53095,19
231,2013.500,4,2147.376,3,24.96299,121.51284,33.4
232,2012.833,16.2,4074.736,0,24.94235,121.50357,14.7
233,2012.917,27.1,4412.765,1,24.95032,121.49587,17.4
234,2013.333,39.7,333.3679,9,24.98016,121.53932,32.4
235,2013.250,8,2216.612,4,24.96007,121.51361,23.9
236,2012.750,12.9,250.631,7,24.96606,121.54297,39.3
237,2013.167,3.6,373.8389,10,24.98322,121.53765,61.9
238,2013.167,13,732.8528,0,24.97668,121.52518,39
239,2013.083,12.8,732.8528,0,24.97668,121.52518,40.6
240,2013.500,18.1,837.7233,0,24.96334,121.54767,29.7
241,2013.083,11,1712.632,2,24.96412,121.5167,28.8
242,2013.500,13.7,250.631,7,24.96606,121.54297,41.4
243,2012.833,2,2077.39,3,24.96357,121.51329,33.4
244,2013.417,32.8,204.1705,8,24.98236,121.53923,48.2
245,2013.083,4.8,1559.827,3,24.97213,121.51627,21.7
246,2013.417,7.5,639.6198,5,24.97258,121.54814,40.8
247,2013.417,16.4,389.8219,6,24.96412,121.54273,40.6
248,2013.333,21.7,1055.067,0,24.96211,121.54928,23.1
249,2013.000,19,1009.235,0,24.96357,121.54951,22.3
250,2012.833,18,6306.153,1,24.95743,121.47516,15
251,2013.167,39.2,424.7132,7,24.97429,121.53917,30
252,2012.917,31.7,1159.454,0,24.9496,121.53018,13.8
253,2012.833,5.9,90.45606,9,24.97433,121.5431,52.7
254,2012.667,30.4,1735.595,2,24.96464,121.51623,25.9
255,2012.667,1.1,329.9747,5,24.98254,121.54395,51.8
256,2013.417,31.5,5512.038,1,24.95095,121.48458,17.4
257,2012.667,14.6,339.2289,1,24.97519,121.53151,26.5
258,2013.250,17.3,444.1334,1,24.97501,121.5273,43.9
259,2013.417,0,292.9978,6,24.97744,121.54458,63.3
260,2013.083,17.7,837.7233,0,24.96334,121.54767,28.8
261,2013.250,17,1485.097,4,24.97073,121.517,30.7
262,2013.167,16.2,2288.011,3,24.95885,121.51359,24.4
263,2012.917,15.9,289.3248,5,24.98203,121.54348,53
264,2013.417,3.9,2147.376,3,24.96299,121.51284,31.7
265,2013.167,32.6,493.657,7,24.96968,121.54522,40.6
266,2012.833,15.7,815.9314,4,24.97886,121.53464,38.1
267,2013.250,17.8,1783.18,3,24.96731,121.51486,23.7
268,2012.833,34.7,482.7581,5,24.97433,121.53863,41.1
269,2013.417,17.2,390.5684,5,24.97937,121.54245,40.1
270,2013.000,17.6,837.7233,0,24.96334,121.54767,23
271,2013.333,10.8,252.5822,1,24.9746,121.53046,117.5
272,2012.917,17.7,451.6419,8,24.96945,121.5449,26.5
273,2012.750,13,492.2313,5,24.96515,121.53737,40.5
274,2013.417,13.2,170.1289,1,24.97371,121.52984,29.3
275,2013.167,27.5,394.0173,7,24.97305,121.53994,41
276,2012.667,1.5,23.38284,7,24.96772,121.54102,49.7
277,2013.000,19.1,461.1016,5,24.95425,121.5399,34
278,2013.417,21.2,2185.128,3,24.96322,121.51237,27.7
279,2012.750,0,208.3905,6,24.95618,121.53844,44
280,2013.417,2.6,1554.25,3,24.97026,121.51642,31.1
281,2013.250,2.3,184.3302,6,24.96581,121.54086,45.4
282,2013.333,4.7,387.7721,9,24.98118,121.53788,44.8
283,2012.917,2,1455.798,1,24.9512,121.549,25.6
284,2013.417,33.5,1978.671,2,24.98674,121.51844,23.5
285,2012.917,15,383.2805,7,24.96735,121.54464,34.4
286,2013.167,30.1,718.2937,3,24.97509,121.53644,55.3
287,2012.917,5.9,90.45606,9,24.97433,121.5431,56.3
288,2013.000,19.2,461.1016,5,24.95425,121.5399,32.9
289,2013.583,16.6,323.6912,6,24.97841,121.5428,51
290,2013.333,13.9,289.3248,5,24.98203,121.54348,44.5
291,2013.083,37.7,490.3446,0,24.97217,121.53471,37
292,2012.833,3.4,56.47425,7,24.95744,121.53711,54.4
293,2013.083,17.5,395.6747,5,24.95674,121.534,24.5
294,2012.667,12.6,383.2805,7,24.96735,121.54464,42.5
295,2013.500,26.4,335.5273,6,24.9796,121.5414,38.1
296,2013.167,18.2,2179.59,3,24.96299,121.51252,21.8
297,2012.750,12.5,1144.436,4,24.99176,121.53456,34.1
298,2012.833,34.9,567.0349,4,24.97003,121.5458,28.5
299,2013.333,16.7,4082.015,0,24.94155,121.50381,16.7
300,2013.167,33.2,121.7262,10,24.98178,121.54059,46.1
301,2013.083,2.5,156.2442,4,24.96696,121.53992,36.9
302,2012.750,38,461.7848,0,24.97229,121.53445,35.7
303,2013.500,16.5,2288.011,3,24.95885,121.51359,23.2
304,2013.500,38.3,439.7105,0,24.97161,121.53423,38.4
305,2013.417,20,1626.083,3,24.96622,121.51668,29.4
306,2013.083,16.2,289.3248,5,24.98203,121.54348,55
307,2013.500,14.4,169.9803,1,24.97369,121.52979,50.2
308,2012.833,10.3,3079.89,0,24.9546,121.56627,24.7
309,2013.417,16.4,289.3248,5,24.98203,121.54348,53
310,2013.250,30.3,1264.73,0,24.94883,121.52954,19.1
311,2013.583,16.4,1643.499,2,24.95394,121.55174,24.7
312,2013.167,21.3,537.7971,4,24.97425,121.53814,42.2
313,2013.583,35.4,318.5292,9,24.97071,121.54069,78
314,2013.333,8.3,104.8101,5,24.96674,121.54067,42.8
315,2013.250,3.7,577.9615,6,24.97201,121.54722,41.6
316,2013.083,15.6,1756.411,2,24.9832,121.51812,27.3
317,2013.250,13.3,250.631,7,24.96606,121.54297,42
318,2012.750,15.6,752.7669,2,24.97795,121.53451,37.5
319,2013.333,7.1,379.5575,10,24.98343,121.53762,49.8
320,2013.250,34.6,272.6783,5,24.95562,121.53872,26.9
321,2012.750,13.5,4197.349,0,24.93885,121.50383,18.6
322,2012.917,16.9,964.7496,4,24.98872,121.53411,37.7
323,2013.000,12.9,187.4823,1,24.97388,121.52981,33.1
324,2013.417,28.6,197.1338,6,24.97631,121.54436,42.5
325,2012.667,12.4,1712.632,2,24.96412,121.5167,31.3
326,2013.083,36.6,488.8193,8,24.97015,121.54494,38.1
327,2013.500,4.1,56.47425,7,24.95744,121.53711,62.1
328,2013.417,3.5,757.3377,3,24.97538,121.54971,36.7
329,2012.833,15.9,1497.713,3,24.97003,121.51696,23.6
330,2013.000,13.6,4197.349,0,24.93885,121.50383,19.2
331,2013.083,32,1156.777,0,24.94935,121.53046,12.8
332,2013.333,25.6,4519.69,0,24.94826,121.49587,15.6
333,2013.167,39.8,617.7134,2,24.97577,121.53475,39.6
334,2012.750,7.8,104.8101,5,24.96674,121.54067,38.4
335,2012.917,30,1013.341,5,24.99006,121.5346,22.8
336,2013.583,27.3,337.6016,6,24.96431,121.54063,36.5
337,2012.833,5.1,1867.233,2,24.98407,121.51748,35.6
338,2012.833,31.3,600.8604,5,24.96871,121.54651,30.9
339,2012.917,31.5,258.186,9,24.96867,121.54331,36.3
340,2013.333,1.7,329.9747,5,24.98254,121.54395,50.4
341,2013.333,33.6,270.8895,0,24.97281,121.53265,42.9
342,2013.000,13,750.0704,2,24.97371,121.54951,37
343,2012.667,5.7,90.45606,9,24.97433,121.5431,53.5
344,2013.000,33.5,563.2854,8,24.98223,121.53597,46.6
345,2013.500,34.6,3085.17,0,24.998,121.5155,41.2
346,2012.667,0,185.4296,0,24.9711,121.5317,37.9
347,2013.417,13.2,1712.632,2,24.96412,121.5167,30.8
348,2013.583,17.4,6488.021,1,24.95719,121.47353,11.2
349,2012.833,4.6,259.6607,6,24.97585,121.54516,53.7
350,2012.750,7.8,104.8101,5,24.96674,121.54067,47
351,2013.000,13.2,492.2313,5,24.96515,121.53737,42.3
352,2012.833,4,2180.245,3,24.96324,121.51241,28.6
353,2012.833,18.4,2674.961,3,24.96143,121.50827,25.7
354,2013.500,4.1,2147.376,3,24.96299,121.51284,31.3
355,2013.417,12.2,1360.139,1,24.95204,121.54842,30.1
356,2013.250,3.8,383.8624,5,24.98085,121.54391,60.7
357,2012.833,10.3,211.4473,1,24.97417,121.52999,45.3
358,2013.417,0,338.9679,9,24.96853,121.54413,44.9
359,2013.167,1.1,193.5845,6,24.96571,121.54089,45.1
360,2013.500,5.6,2408.993,0,24.95505,121.55964,24.7
361,2012.667,32.9,87.30222,10,24.983,121.54022,47.1
362,2013.083,41.4,281.205,8,24.97345,121.54093,63.3
363,2013.417,17.1,967.4,4,24.98872,121.53408,40
364,2013.500,32.3,109.9455,10,24.98182,121.54086,48
365,2013.417,35.3,614.1394,7,24.97913,121.53666,33.1
366,2012.917,17.3,2261.432,4,24.96182,121.51222,29.5
367,2012.750,14.2,1801.544,1,24.95153,121.55254,24.8
368,2012.833,15,1828.319,2,24.96464,121.51531,20.9
369,2013.417,18.2,350.8515,1,24.97544,121.53119,43.1
370,2012.667,20.2,2185.128,3,24.96322,121.51237,22.8
371,2012.750,15.9,289.3248,5,24.98203,121.54348,42.1
372,2013.500,4.1,312.8963,5,24.95591,121.53956,51.7
373,2013.000,33.9,157.6052,7,24.96628,121.54196,41.5
374,2013.083,0,274.0144,1,24.9748,121.53059,52.2
375,2013.250,5.4,390.5684,5,24.97937,121.54245,49.5
376,2013.250,21.7,1157.988,0,24.96165,121.55011,23.8
377,2013.417,14.7,1717.193,2,24.96447,121.51649,30.5
378,2013.333,3.9,49.66105,8,24.95836,121.53756,56.8
379,2013.333,37.3,587.8877,8,24.97077,121.54634,37.4
380,2013.333,0,292.9978,6,24.97744,121.54458,69.7
381,2013.333,14.1,289.3248,5,24.98203,121.54348,53.3
382,2013.417,8,132.5469,9,24.98298,121.53981,47.3
383,2013.000,16.3,3529.564,0,24.93207,121.51597,29.3
384,2012.667,29.1,506.1144,4,24.97845,121.53889,40.3
385,2012.750,16.1,4066.587,0,24.94297,121.50342,12.9
386,2013.000,18.3,82.88643,10,24.983,121.54026,46.6
387,2012.833,0,185.4296,0,24.9711,121.5317,55.3
388,2013.250,16.2,2103.555,3,24.96042,121.51462,25.6
389,2013.500,10.4,2251.938,4,24.95957,121.51353,27.3
390,2013.250,40.9,122.3619,8,24.96756,121.5423,67.7
391,2013.500,32.8,377.8302,9,24.97151,121.5435,38.6
392,2013.583,6.2,1939.749,1,24.95155,121.55387,31.3
393,2013.083,42.7,443.802,6,24.97927,121.53874,35.3
394,2013.000,16.9,967.4,4,24.98872,121.53408,40.3
395,2013.500,32.6,4136.271,1,24.95544,121.4963,24.7
396,2012.917,21.2,512.5487,4,24.974,121.53842,42.5
397,2012.667,37.1,918.6357,1,24.97198,121.55063,31.9
398,2013.417,13.1,1164.838,4,24.99156,121.53406,32.2
399,2013.417,14.7,1717.193,2,24.96447,121.51649,23
400,2012.917,12.7,170.1289,1,24.97371,121.52984,37.3
401,2013.250,26.8,482.7581,5,24.97433,121.53863,35.5
402,2013.083,7.6,2175.03,3,24.96305,121.51254,27.7
403,2012.833,12.7,187.4823,1,24.97388,121.52981,28.5
404,2012.667,30.9,161.942,9,24.98353,121.53966,39.7
405,2013.333,16.4,289.3248,5,24.98203,121.54348,41.2
406,2012.667,23,130.9945,6,24.95663,121.53765,37.2
407,2013.167,1.9,372.1386,7,24.97293,121.54026,40.5
408,2013.000,5.2,2408.993,0,24.95505,121.55964,22.3
409,2013.417,18.5,2175.744,3,24.9633,121.51243,28.1
410,2013.000,13.7,4082.015,0,24.94155,121.50381,15.4
411,2012.667,5.6,90.45606,9,24.97433,121.5431,50
412,2013.250,18.8,390.9696,7,24.97923,121.53986,40.6
413,2013.000,8.1,104.8101,5,24.96674,121.54067,52.5
414,2013.500,6.5,90.45606,9,24.97433,121.5431,63.9
" download="Real estate.csv">Download Real estate.csv</a>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="simple-linear-regression.html#cb174-1" aria-hidden="true" tabindex="-1"></a>houses <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Real estate.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb174-2"><a href="simple-linear-regression.html#cb174-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(houses<span class="sc">$</span>X2.house.age, houses<span class="sc">$</span>Y.house.price.of.unit.area, <span class="at">xlab =</span> <span class="st">&#39;age&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;price by unit area&#39;</span>)</span></code></pre></div>
<p><img src="15-Regression_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div id="fitting-the-regression" class="section level3 hasAnchor" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> Fitting the regression<a href="simple-linear-regression.html#fitting-the-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>From the output of the summary of teh lm fit we see that the fitted regression line is
<span class="math display">\[\text{Price by unit area } = 42.4347 - 0.2515\text{ age}. \]</span>
The estimated variance is <span class="math inline">\(MSE = \hat\sigma^2 = 13.32^2\)</span>.</p>
<p>We have the observed test statistics:
<span class="math display">\[\frac{\hat\beta_0}{\sqrt{\frac{MSE n^{-1}\sum x_i^2}{\sum(x_i - \overline x)^2}}} = 35.042\]</span>
and
<span class="math display">\[\frac{\hat\beta_1}{\sqrt{\frac{MSE }{\sum(x_i - \overline x)^2}}} = -4.372\]</span>
which are both significant, meaning the intercept and slope are not zero.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="simple-linear-regression.html#cb175-1" aria-hidden="true" tabindex="-1"></a>my.lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y.house.price.of.unit.area<span class="sc">~</span>X2.house.age, <span class="at">data =</span> houses)</span>
<span id="cb175-2"><a href="simple-linear-regression.html#cb175-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(my.lm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y.house.price.of.unit.area ~ X2.house.age, data = houses)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -31.113 -10.738   1.626   8.199  77.781 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  42.43470    1.21098  35.042  &lt; 2e-16 ***
## X2.house.age -0.25149    0.05752  -4.372 1.56e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 13.32 on 412 degrees of freedom
## Multiple R-squared:  0.04434,    Adjusted R-squared:  0.04202 
## F-statistic: 19.11 on 1 and 412 DF,  p-value: 1.56e-05</code></pre>
<p>The fitted line, overlaid on the data:</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="simple-linear-regression.html#cb177-1" aria-hidden="true" tabindex="-1"></a>houses <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Real estate.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb177-2"><a href="simple-linear-regression.html#cb177-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(houses<span class="sc">$</span>X2.house.age, houses<span class="sc">$</span>Y.house.price.of.unit.area, <span class="at">xlab =</span> <span class="st">&#39;age&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;price by unit area&#39;</span>)</span>
<span id="cb177-3"><a href="simple-linear-regression.html#cb177-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="fl">42.43470</span>, <span class="at">b =</span> <span class="sc">-</span>.<span class="dv">25149</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="15-Regression_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Predicting the home price of a house that is 20 years old:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="simple-linear-regression.html#cb178-1" aria-hidden="true" tabindex="-1"></a>my.summ <span class="ot">&lt;-</span> <span class="fu">summary</span>(my.lm)</span>
<span id="cb178-2"><a href="simple-linear-regression.html#cb178-2" aria-hidden="true" tabindex="-1"></a>MSE <span class="ot">&lt;-</span> my.summ<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb178-3"><a href="simple-linear-regression.html#cb178-3" aria-hidden="true" tabindex="-1"></a>n<span class="ot">&lt;-</span> <span class="fu">length</span>(houses<span class="sc">$</span>Y.house.price.of.unit.area)</span>
<span id="cb178-4"><a href="simple-linear-regression.html#cb178-4" aria-hidden="true" tabindex="-1"></a>se.term <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span>n <span class="sc">+</span> ((<span class="dv">20</span><span class="sc">-</span><span class="fu">mean</span>(houses<span class="sc">$</span>X2.house.age))<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="fu">sum</span>((houses<span class="sc">$</span>X2.house.age <span class="sc">-</span> <span class="fu">mean</span>(houses<span class="sc">$</span>X2.house.age))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb178-5"><a href="simple-linear-regression.html#cb178-5" aria-hidden="true" tabindex="-1"></a>PI <span class="ot">&lt;-</span> <span class="fu">c</span>(my.summ<span class="sc">$</span>coefficients[<span class="dv">1</span>] <span class="sc">+</span> my.summ<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span><span class="dv">20</span> <span class="sc">+</span> <span class="fu">qt</span>(<span class="fl">0.025</span>, my.summ<span class="sc">$</span>df[<span class="dv">2</span>])<span class="sc">*</span><span class="fu">sqrt</span>(MSE<span class="sc">*</span>se.term), my.summ<span class="sc">$</span>coefficients[<span class="dv">1</span>] <span class="sc">+</span> my.summ<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span><span class="dv">20</span> <span class="sc">+</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, my.summ<span class="sc">$</span>df[<span class="dv">2</span>])<span class="sc">*</span><span class="fu">sqrt</span>(MSE<span class="sc">*</span>se.term))</span>
<span id="cb178-6"><a href="simple-linear-regression.html#cb178-6" aria-hidden="true" tabindex="-1"></a>PI</span></code></pre></div>
<pre><code>## [1] 11.19322 63.61663</code></pre>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="simple-linear-regression.html#cb180-1" aria-hidden="true" tabindex="-1"></a>houses <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Real estate.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb180-2"><a href="simple-linear-regression.html#cb180-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(houses<span class="sc">$</span>X2.house.age, houses<span class="sc">$</span>Y.house.price.of.unit.area, <span class="at">xlab =</span> <span class="st">&#39;age&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;price by unit area&#39;</span>)</span>
<span id="cb180-3"><a href="simple-linear-regression.html#cb180-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="fl">42.43470</span>, <span class="at">b =</span> <span class="sc">-</span>.<span class="dv">25149</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb180-4"><a href="simple-linear-regression.html#cb180-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">20</span>,<span class="dv">20</span>), PI, <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">type =</span> <span class="st">&#39;o&#39;</span>)</span></code></pre></div>
<p><img src="15-Regression_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Simultaneous Confidence bands:</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="simple-linear-regression.html#cb181-1" aria-hidden="true" tabindex="-1"></a>my.summ <span class="ot">&lt;-</span> <span class="fu">summary</span>(my.lm)</span>
<span id="cb181-2"><a href="simple-linear-regression.html#cb181-2" aria-hidden="true" tabindex="-1"></a>MSE <span class="ot">&lt;-</span> my.summ<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb181-3"><a href="simple-linear-regression.html#cb181-3" aria-hidden="true" tabindex="-1"></a>n<span class="ot">&lt;-</span> <span class="fu">length</span>(houses<span class="sc">$</span>Y.house.price.of.unit.area)</span>
<span id="cb181-4"><a href="simple-linear-regression.html#cb181-4" aria-hidden="true" tabindex="-1"></a>se.term0 <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">/</span>n)<span class="sc">*</span><span class="fu">sum</span>(houses<span class="sc">$</span>X2.house.age<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="fu">sum</span>((houses<span class="sc">$</span>X2.house.age <span class="sc">-</span> <span class="fu">mean</span>(houses<span class="sc">$</span>X2.house.age))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb181-5"><a href="simple-linear-regression.html#cb181-5" aria-hidden="true" tabindex="-1"></a>se.term1 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">sum</span>((houses<span class="sc">$</span>X2.house.age <span class="sc">-</span> <span class="fu">mean</span>(houses<span class="sc">$</span>X2.house.age))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb181-6"><a href="simple-linear-regression.html#cb181-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-7"><a href="simple-linear-regression.html#cb181-7" aria-hidden="true" tabindex="-1"></a>beta0.intv <span class="ot">&lt;-</span> <span class="fu">c</span>(my.summ<span class="sc">$</span>coefficients[<span class="dv">1</span>] <span class="sc">-</span> <span class="fu">sqrt</span>(<span class="dv">2</span><span class="sc">*</span><span class="fu">qf</span>(<span class="fl">0.95</span>,<span class="dv">2</span>,my.summ<span class="sc">$</span>df[<span class="dv">2</span>])<span class="sc">*</span>MSE<span class="sc">*</span>se.term0), my.summ<span class="sc">$</span>coefficients[<span class="dv">1</span>] <span class="sc">+</span> <span class="fu">sqrt</span>(<span class="dv">2</span><span class="sc">*</span><span class="fu">qf</span>(<span class="fl">0.95</span>,<span class="dv">2</span>,my.summ<span class="sc">$</span>df[<span class="dv">2</span>])<span class="sc">*</span>MSE<span class="sc">*</span>se.term0))</span>
<span id="cb181-8"><a href="simple-linear-regression.html#cb181-8" aria-hidden="true" tabindex="-1"></a>beta1.intv <span class="ot">&lt;-</span> <span class="fu">c</span>(my.summ<span class="sc">$</span>coefficients[<span class="dv">2</span>] <span class="sc">-</span> <span class="fu">sqrt</span>(<span class="dv">2</span><span class="sc">*</span><span class="fu">qf</span>(<span class="fl">0.95</span>,<span class="dv">2</span>,my.summ<span class="sc">$</span>df[<span class="dv">2</span>])<span class="sc">*</span>MSE<span class="sc">*</span>se.term1), my.summ<span class="sc">$</span>coefficients[<span class="dv">2</span>] <span class="sc">+</span> <span class="fu">sqrt</span>(<span class="dv">2</span><span class="sc">*</span><span class="fu">qf</span>(<span class="fl">0.95</span>,<span class="dv">2</span>,my.summ<span class="sc">$</span>df[<span class="dv">2</span>])<span class="sc">*</span>MSE<span class="sc">*</span>se.term1))</span></code></pre></div>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="simple-linear-regression.html#cb182-1" aria-hidden="true" tabindex="-1"></a>houses <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Real estate.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb182-2"><a href="simple-linear-regression.html#cb182-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(houses<span class="sc">$</span>X2.house.age, houses<span class="sc">$</span>Y.house.price.of.unit.area, <span class="at">xlab =</span> <span class="st">&#39;age&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;price by unit area&#39;</span>)</span>
<span id="cb182-3"><a href="simple-linear-regression.html#cb182-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="fl">42.43470</span>, <span class="at">b =</span> <span class="sc">-</span>.<span class="dv">25149</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb182-4"><a href="simple-linear-regression.html#cb182-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> beta0.intv[<span class="dv">1</span>], <span class="at">b =</span> beta1.intv[<span class="dv">1</span>], <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb182-5"><a href="simple-linear-regression.html#cb182-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> beta0.intv[<span class="dv">2</span>], <span class="at">b =</span> beta1.intv[<span class="dv">2</span>], <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="15-Regression_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Pointwise confidence bands using CIs for conditional mean responses:</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="simple-linear-regression.html#cb183-1" aria-hidden="true" tabindex="-1"></a>my.summ <span class="ot">&lt;-</span> <span class="fu">summary</span>(my.lm)</span>
<span id="cb183-2"><a href="simple-linear-regression.html#cb183-2" aria-hidden="true" tabindex="-1"></a>MSE <span class="ot">&lt;-</span> my.summ<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb183-3"><a href="simple-linear-regression.html#cb183-3" aria-hidden="true" tabindex="-1"></a>n<span class="ot">&lt;-</span> <span class="fu">length</span>(houses<span class="sc">$</span>Y.house.price.of.unit.area)</span>
<span id="cb183-4"><a href="simple-linear-regression.html#cb183-4" aria-hidden="true" tabindex="-1"></a>CI.fun <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb183-5"><a href="simple-linear-regression.html#cb183-5" aria-hidden="true" tabindex="-1"></a>  se.term <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>n <span class="sc">+</span> ((x<span class="sc">-</span><span class="fu">mean</span>(houses<span class="sc">$</span>X2.house.age))<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="fu">sum</span>((houses<span class="sc">$</span>X2.house.age <span class="sc">-</span> <span class="fu">mean</span>(houses<span class="sc">$</span>X2.house.age))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb183-6"><a href="simple-linear-regression.html#cb183-6" aria-hidden="true" tabindex="-1"></a>  ci <span class="ot">&lt;-</span> <span class="fu">c</span>(my.summ<span class="sc">$</span>coefficients[<span class="dv">1</span>] <span class="sc">+</span> my.summ<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>x <span class="sc">+</span> <span class="fu">qt</span>(<span class="fl">0.025</span>, my.summ<span class="sc">$</span>df[<span class="dv">2</span>])<span class="sc">*</span><span class="fu">sqrt</span>(MSE<span class="sc">*</span>se.term), my.summ<span class="sc">$</span>coefficients[<span class="dv">1</span>] <span class="sc">+</span> my.summ<span class="sc">$</span>coefficients[<span class="dv">2</span>]<span class="sc">*</span>x <span class="sc">+</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, my.summ<span class="sc">$</span>df[<span class="dv">2</span>])<span class="sc">*</span><span class="fu">sqrt</span>(MSE<span class="sc">*</span>se.term))</span>
<span id="cb183-7"><a href="simple-linear-regression.html#cb183-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(ci)</span>
<span id="cb183-8"><a href="simple-linear-regression.html#cb183-8" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Pointwise intervals in green:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="simple-linear-regression.html#cb184-1" aria-hidden="true" tabindex="-1"></a>houses <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Real estate.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb184-2"><a href="simple-linear-regression.html#cb184-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(houses<span class="sc">$</span>X2.house.age, houses<span class="sc">$</span>Y.house.price.of.unit.area, <span class="at">xlab =</span> <span class="st">&#39;age&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;price by unit area&#39;</span>)</span>
<span id="cb184-3"><a href="simple-linear-regression.html#cb184-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="fl">42.43470</span>, <span class="at">b =</span> <span class="sc">-</span>.<span class="dv">25149</span>, <span class="at">col =</span> <span class="st">&#39;blue&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb184-4"><a href="simple-linear-regression.html#cb184-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb184-5"><a href="simple-linear-regression.html#cb184-5" aria-hidden="true" tabindex="-1"></a>x.seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">50</span>, <span class="at">length.out =</span> <span class="dv">400</span>)</span>
<span id="cb184-6"><a href="simple-linear-regression.html#cb184-6" aria-hidden="true" tabindex="-1"></a>app.fun <span class="ot">&lt;-</span> <span class="fu">apply</span>(<span class="fu">matrix</span>(x.seq, <span class="dv">400</span>,<span class="dv">1</span>),<span class="dv">1</span>,CI.fun)</span>
<span id="cb184-7"><a href="simple-linear-regression.html#cb184-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x.seq, app.fun[<span class="dv">1</span>,], <span class="at">col =</span> <span class="st">&#39;green&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb184-8"><a href="simple-linear-regression.html#cb184-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x.seq, app.fun[<span class="dv">2</span>,], <span class="at">col =</span> <span class="st">&#39;green&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb184-9"><a href="simple-linear-regression.html#cb184-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> beta0.intv[<span class="dv">1</span>], <span class="at">b =</span> beta1.intv[<span class="dv">1</span>], <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb184-10"><a href="simple-linear-regression.html#cb184-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> beta0.intv[<span class="dv">2</span>], <span class="at">b =</span> beta1.intv[<span class="dv">2</span>], <span class="at">col =</span> <span class="st">&#39;red&#39;</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="15-Regression_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="anova.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/15-Regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
